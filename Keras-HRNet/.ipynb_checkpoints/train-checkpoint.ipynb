{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 加载依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Permute, Dense, Activation, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPool2D, BatchNormalization\n",
    "from keras.layers import Convolution2D, UpSampling2D, AtrousConvolution2D, ZeroPadding2D, Lambda, Conv2DTranspose\n",
    "from keras.layers import multiply, add, concatenate, Concatenate\n",
    "from keras.layers import LocallyConnected2D\n",
    "from keras.layers import add\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import cv2\n",
    "import random\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "import tifffile\n",
    "from keras.backend import tf as ktf\n",
    "from glob import glob\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASS = 5\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "\n",
    "# 数据路径\n",
    "img_type = '.tif'\n",
    "TRAIN_TOP_PATH = 'E:/Semantic-Segmentation/four_dataset/VAIHINGEN/train_crop_top/'\n",
    "\n",
    "VAL_TOP_PATH = 'E:/Semantic-Segmentation/four_dataset/VAIHINGEN/test_crop_top/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import UpSampling2D, add, concatenate, Dropout\n",
    "from keras_superpixel_pooling_new import *\n",
    "from keras_superpixel_unpooling_new import *\n",
    "\n",
    "\n",
    "def conv3x3(x, out_filters, strides=(1, 1)):\n",
    "    x = Conv2D(out_filters, 3, padding='same', strides=strides, use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def basic_Block(input, out_filters, strides=(1, 1), with_conv_shortcut=False):\n",
    "    x = conv3x3(input, out_filters, strides)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = conv3x3(x, out_filters)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    if with_conv_shortcut:\n",
    "        residual = Conv2D(out_filters, 1, strides=strides, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "        residual = BatchNormalization(axis=3)(residual)\n",
    "        x = add([x, residual])\n",
    "    else:\n",
    "        x = add([x, input])\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bottleneck_Block(input, out_filters, strides=(1, 1), with_conv_shortcut=False):\n",
    "    expansion = 4\n",
    "    de_filters = int(out_filters / expansion)\n",
    "\n",
    "    x = Conv2D(de_filters, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(de_filters, 3, strides=strides, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(out_filters, 1, use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    if with_conv_shortcut:\n",
    "        residual = Conv2D(out_filters, 1, strides=strides, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "        residual = BatchNormalization(axis=3)(residual)\n",
    "        x = add([x, residual])\n",
    "    else:\n",
    "        x = add([x, input])\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def stem_net(input):\n",
    "    x = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(input)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # x = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization(axis=3)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_layer1(x, out_filters_list=[32, 64]):\n",
    "    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x0 = BatchNormalization(axis=3)(x0)\n",
    "    x0 = Activation('relu')(x0)\n",
    "\n",
    "    x1 = Conv2D(out_filters_list[1], 3, strides=(2, 2),\n",
    "                padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x1 = BatchNormalization(axis=3)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    return [x0, x1]\n",
    "\n",
    "\n",
    "def make_branch1_0(x, out_filters=32):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch1_1(x, out_filters=64):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fuse_layer1(x):\n",
    "    x0_0 = x[0]\n",
    "    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x0_1 = BatchNormalization(axis=3)(x0_1)\n",
    "    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n",
    "    x0 = add([x0_0, x0_1])\n",
    "\n",
    "    x1_0 = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x1_0 = BatchNormalization(axis=3)(x1_0)\n",
    "    x1_1 = x[1]\n",
    "    x1 = add([x1_0, x1_1])\n",
    "    return [x0, x1]\n",
    "\n",
    "\n",
    "def transition_layer2(x, out_filters_list=[32, 64, 128]):\n",
    "    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x0 = BatchNormalization(axis=3)(x0)\n",
    "    x0 = Activation('relu')(x0)\n",
    "\n",
    "    x1 = Conv2D(out_filters_list[1], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x1 = BatchNormalization(axis=3)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv2D(out_filters_list[2], 3, strides=(2, 2),\n",
    "                padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x2 = BatchNormalization(axis=3)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    return [x0, x1, x2]\n",
    "\n",
    "\n",
    "def make_branch2_0(x, out_filters=32):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch2_1(x, out_filters=64):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch2_2(x, out_filters=128):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fuse_layer2(x):\n",
    "    x0_0 = x[0]\n",
    "    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x0_1 = BatchNormalization(axis=3)(x0_1)\n",
    "    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n",
    "    x0_2 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x0_2 = BatchNormalization(axis=3)(x0_2)\n",
    "    x0_2 = UpSampling2D(size=(4, 4))(x0_2)\n",
    "    x0 = add([x0_0, x0_1, x0_2])\n",
    "\n",
    "    x1_0 = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x1_0 = BatchNormalization(axis=3)(x1_0)\n",
    "    x1_1 = x[1]\n",
    "    x1_2 = Conv2D(64, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x1_2 = BatchNormalization(axis=3)(x1_2)\n",
    "    x1_2 = UpSampling2D(size=(2, 2))(x1_2)\n",
    "    x1 = add([x1_0, x1_1, x1_2])\n",
    "\n",
    "    x2_0 = Conv2D(32, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x2_0 = BatchNormalization(axis=3)(x2_0)\n",
    "    x2_0 = Activation('relu')(x2_0)\n",
    "    x2_0 = Conv2D(128, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x2_0)\n",
    "    x2_0 = BatchNormalization(axis=3)(x2_0)\n",
    "    x2_1 = Conv2D(128, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x2_1 = BatchNormalization(axis=3)(x2_1)\n",
    "    x2_2 = x[2]\n",
    "    x2 = add([x2_0, x2_1, x2_2])\n",
    "    return [x0, x1, x2]\n",
    "\n",
    "\n",
    "def transition_layer3(x, out_filters_list=[32, 64, 128, 256]):\n",
    "    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x0 = BatchNormalization(axis=3)(x0)\n",
    "    x0 = Activation('relu')(x0)\n",
    "\n",
    "    x1 = Conv2D(out_filters_list[1], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x1 = BatchNormalization(axis=3)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv2D(out_filters_list[2], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x2 = BatchNormalization(axis=3)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv2D(out_filters_list[3], 3, strides=(2, 2),\n",
    "                padding='same', use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x3 = BatchNormalization(axis=3)(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    return [x0, x1, x2, x3]\n",
    "\n",
    "\n",
    "def make_branch3_0(x, out_filters=32):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch3_1(x, out_filters=64):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch3_2(x, out_filters=128):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch3_3(x, out_filters=256):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fuse_layer3(x):\n",
    "    x0_0 = x[0]\n",
    "    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x0_1 = BatchNormalization(axis=3)(x0_1)\n",
    "    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n",
    "    x0_2 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x0_2 = BatchNormalization(axis=3)(x0_2)\n",
    "    x0_2 = UpSampling2D(size=(4, 4))(x0_2)\n",
    "    x0_3 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[3])\n",
    "    x0_3 = BatchNormalization(axis=3)(x0_3)\n",
    "    x0_3 = UpSampling2D(size=(8, 8))(x0_3)\n",
    "    x0 = concatenate([x0_0, x0_1, x0_2, x0_3], axis=-1)\n",
    "    return x0\n",
    "\n",
    "\n",
    "def final_layer(x, classes=1):\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(classes, 1, use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('softmax', name='Classification')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def seg_hrnet(batch=1, height=256, width=256, channel=3, classes=6):\n",
    "    inputs = Input(batch_shape=(batch,) + (height, width, channel))\n",
    "    slic_feature_map = Input(batch_shape=(batch,) + (height, width))\n",
    "\n",
    "    x0 = stem_net(inputs)\n",
    "\n",
    "    x1 = transition_layer1(x0)\n",
    "    x1_0 = make_branch1_0(x1[0])\n",
    "    x1_1 = make_branch1_1(x1[1])\n",
    "    x1 = fuse_layer1([x1_0, x1_1])\n",
    "\n",
    "    x2 = transition_layer2(x1)\n",
    "    x2_0 = make_branch2_0(x2[0])\n",
    "    x2_1 = make_branch2_1(x2[1])\n",
    "    x2_2 = make_branch2_2(x2[2])\n",
    "    x2 = fuse_layer2([x2_0, x2_1, x2_2])\n",
    "\n",
    "    x3 = transition_layer3(x2)\n",
    "    x3_0 = make_branch3_0(x3[0])\n",
    "    x3_1 = make_branch3_1(x3[1])\n",
    "    x3_2 = make_branch3_2(x3[2])\n",
    "    x3_3 = make_branch3_3(x3[3])\n",
    "    x3 = fuse_layer3([x3_0, x3_1, x3_2, x3_3])\n",
    "    x3 = UpSampling2D(size=(2, 2))(x3)\n",
    "\n",
    "    # ORIGINAL\n",
    "    x4_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x3)\n",
    "    x4_1 = BatchNormalization(axis=-1)(x4_1)\n",
    "\n",
    "    # SUPERPIXEL\n",
    "    x4_2 = SuperpixelPooling(num_superpixels=100)([x3, slic_feature_map])\n",
    "    x4_2 = Conv1D(32, 1, use_bias=False, kernel_initializer='he_normal')(x4_2)\n",
    "    x4_2 = BatchNormalization(axis=-1)(x4_2)\n",
    "    x4_2 = SuperpixelUnpooling(num_superpixels=100)([x4_2, slic_feature_map])\n",
    "    print(x4_2)\n",
    "\n",
    "    x4 = add([x4_1, x4_2])\n",
    "\n",
    "    out = final_layer(x4_1, classes=classes)\n",
    "\n",
    "    model = Model(inputs=[inputs, slic_feature_map], outputs=[out])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 数据加载generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 读取一个batch的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "# 读取图片函数\n",
    "def read_img(top_paths):\n",
    "    top_imgs = []\n",
    "    label_imgs = []\n",
    "    slic_segs = []\n",
    "    for top_path in top_paths:\n",
    "        label_path = top_path.replace('top', 'label')\n",
    "        \n",
    "        top_img = tifffile.imread(top_path)\n",
    "        label_img = tifffile.imread(label_path)\n",
    "        slic_seg = slic(top_img, n_segments=100, compactness=30, max_iter=10, convert2lab=False, enforce_connectivity=False)\n",
    "        \n",
    "        top_img = top_img / 255.0\n",
    "        \n",
    "        label_img = np.expand_dims(label_img, axis=2)\n",
    "        label_img = np_utils.to_categorical(label_img, num_classes=6)\n",
    "        label_img = label_img[:, :, 0:5]\n",
    "\n",
    "        top_imgs.append(top_img)\n",
    "        label_imgs.append(label_img)\n",
    "        slic_segs.append(slic_seg)\n",
    "\n",
    "    return np.array(top_imgs), np.array(label_imgs), np.array(slic_segs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 获取批次函数，其实就是一个generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(top_path, batch_size):\n",
    "    while 1:\n",
    "        for i in range(0, len(top_path), batch_size):\n",
    "            top, label, slic_seg = read_img(top_path[i:i + batch_size])\n",
    "\n",
    "            yield ([{'input_1': ]top, 'input_2': slic_seg}, {'Classification': label})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 读取数据路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_paths(train_crop_top_dir, test_crop_top_dir):\n",
    "    train_crop_top_paths = glob(os.path.join(train_crop_top_dir, '*.tif'))\n",
    "    test_crop_top_paths = glob(os.path.join(test_crop_top_dir, '*.tif'))\n",
    "\n",
    "    # 随机打乱训练数据\n",
    "    index = [m for m in range(len(train_crop_top_paths))]\n",
    "    random.shuffle(index)\n",
    "    train_crop_top_paths = np.array(train_crop_top_paths)[index]\n",
    "\n",
    "    print(index)\n",
    "    return train_crop_top_paths, test_crop_top_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 定义评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"superpixel_unpooling_1/Reshape_5:0\", shape=(1, 512, 512, 32), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (1, 512, 512, 3)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (1, 256, 256, 64)    1728        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (1, 256, 256, 64)    256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (1, 256, 256, 64)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (1, 256, 256, 64)    4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (1, 256, 256, 64)    256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (1, 256, 256, 64)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (1, 256, 256, 64)    36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (1, 256, 256, 64)    256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (1, 256, 256, 64)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (1, 256, 256, 256)   16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (1, 256, 256, 256)   16384       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (1, 256, 256, 256)   1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (1, 256, 256, 256)   1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (1, 256, 256, 256)   0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (1, 256, 256, 256)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (1, 256, 256, 64)    16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (1, 256, 256, 64)    256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (1, 256, 256, 64)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (1, 256, 256, 64)    36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (1, 256, 256, 64)    256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (1, 256, 256, 64)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (1, 256, 256, 256)   16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (1, 256, 256, 256)   1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (1, 256, 256, 256)   0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (1, 256, 256, 256)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (1, 256, 256, 64)    16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (1, 256, 256, 64)    256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (1, 256, 256, 64)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (1, 256, 256, 64)    36864       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (1, 256, 256, 64)    256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (1, 256, 256, 64)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (1, 256, 256, 256)   16384       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (1, 256, 256, 256)   1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (1, 256, 256, 256)   0           batch_normalization_11[0][0]     \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (1, 256, 256, 256)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (1, 256, 256, 64)    16384       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (1, 256, 256, 64)    256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (1, 256, 256, 64)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (1, 256, 256, 64)    36864       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (1, 256, 256, 64)    256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (1, 256, 256, 64)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (1, 256, 256, 256)   16384       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (1, 256, 256, 256)   1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (1, 256, 256, 256)   0           batch_normalization_14[0][0]     \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (1, 256, 256, 256)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (1, 128, 128, 64)    147456      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (1, 128, 128, 64)    256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (1, 128, 128, 64)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (1, 256, 256, 32)    73728       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (1, 128, 128, 64)    36864       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (1, 256, 256, 32)    128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (1, 128, 128, 64)    256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (1, 256, 256, 32)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (1, 128, 128, 64)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (1, 256, 256, 32)    9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (1, 128, 128, 64)    36864       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (1, 256, 256, 32)    128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (1, 128, 128, 64)    256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (1, 256, 256, 32)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (1, 128, 128, 64)    0           batch_normalization_26[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (1, 256, 256, 32)    9216        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (1, 128, 128, 64)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (1, 256, 256, 32)    128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (1, 128, 128, 64)    36864       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (1, 256, 256, 32)    0           batch_normalization_18[0][0]     \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (1, 128, 128, 64)    256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (1, 256, 256, 32)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (1, 128, 128, 64)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (1, 256, 256, 32)    9216        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (1, 128, 128, 64)    36864       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (1, 256, 256, 32)    128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (1, 128, 128, 64)    256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (1, 256, 256, 32)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (1, 128, 128, 64)    0           batch_normalization_28[0][0]     \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (1, 256, 256, 32)    9216        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (1, 128, 128, 64)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (1, 256, 256, 32)    128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (1, 128, 128, 64)    36864       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (1, 256, 256, 32)    0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (1, 128, 128, 64)    256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (1, 256, 256, 32)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (1, 128, 128, 64)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (1, 256, 256, 32)    9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (1, 128, 128, 64)    36864       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (1, 256, 256, 32)    128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (1, 128, 128, 64)    256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (1, 256, 256, 32)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (1, 128, 128, 64)    0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (1, 256, 256, 32)    9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (1, 128, 128, 64)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (1, 256, 256, 32)    128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (1, 128, 128, 64)    36864       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (1, 256, 256, 32)    0           batch_normalization_22[0][0]     \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (1, 128, 128, 64)    256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (1, 256, 256, 32)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (1, 128, 128, 64)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (1, 256, 256, 32)    9216        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (1, 128, 128, 64)    36864       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (1, 256, 256, 32)    128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (1, 128, 128, 64)    256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (1, 256, 256, 32)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (1, 128, 128, 64)    0           batch_normalization_32[0][0]     \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (1, 256, 256, 32)    9216        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (1, 128, 128, 64)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (1, 256, 256, 32)    128         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (1, 128, 128, 32)    2048        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (1, 256, 256, 32)    0           batch_normalization_24[0][0]     \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (1, 128, 128, 32)    128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (1, 256, 256, 32)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (1, 256, 256, 32)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (1, 256, 256, 32)    0           activation_23[0][0]              \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (1, 128, 128, 64)    18432       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (1, 256, 256, 32)    9216        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (1, 128, 128, 64)    256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (1, 256, 256, 32)    128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (1, 128, 128, 64)    0           batch_normalization_34[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (1, 256, 256, 32)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (1, 64, 64, 128)     73728       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (1, 256, 256, 32)    9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (1, 128, 128, 64)    36864       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (1, 64, 64, 128)     512         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (1, 256, 256, 32)    128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (1, 128, 128, 64)    256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (1, 64, 64, 128)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (1, 256, 256, 32)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (1, 128, 128, 64)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (1, 64, 64, 128)     147456      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (1, 256, 256, 32)    9216        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (1, 128, 128, 64)    36864       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (1, 64, 64, 128)     512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (1, 256, 256, 32)    128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (1, 128, 128, 64)    256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (1, 64, 64, 128)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (1, 256, 256, 32)    0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (1, 128, 128, 64)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (1, 64, 64, 128)     147456      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (1, 256, 256, 32)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (1, 128, 128, 64)    36864       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (1, 64, 64, 128)     512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (1, 256, 256, 32)    9216        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (1, 128, 128, 64)    256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (1, 64, 64, 128)     0           batch_normalization_55[0][0]     \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (1, 256, 256, 32)    128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (1, 128, 128, 64)    0           batch_normalization_47[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (1, 64, 64, 128)     0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (1, 256, 256, 32)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (1, 128, 128, 64)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (1, 64, 64, 128)     147456      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (1, 256, 256, 32)    9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (1, 128, 128, 64)    36864       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (1, 64, 64, 128)     512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (1, 256, 256, 32)    128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (1, 128, 128, 64)    256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (1, 64, 64, 128)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (1, 256, 256, 32)    0           batch_normalization_41[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (1, 128, 128, 64)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (1, 64, 64, 128)     147456      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (1, 256, 256, 32)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (1, 128, 128, 64)    36864       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (1, 64, 64, 128)     512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (1, 256, 256, 32)    9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (1, 128, 128, 64)    256         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (1, 64, 64, 128)     0           batch_normalization_57[0][0]     \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (1, 256, 256, 32)    128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (1, 128, 128, 64)    0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (1, 64, 64, 128)     0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (1, 256, 256, 32)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (1, 128, 128, 64)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (1, 64, 64, 128)     147456      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (1, 256, 256, 32)    9216        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (1, 128, 128, 64)    36864       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (1, 64, 64, 128)     512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (1, 256, 256, 32)    128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (1, 128, 128, 64)    256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (1, 64, 64, 128)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (1, 256, 256, 32)    0           batch_normalization_43[0][0]     \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (1, 128, 128, 64)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (1, 64, 64, 128)     147456      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (1, 256, 256, 32)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (1, 128, 128, 64)    36864       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (1, 64, 64, 128)     512         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (1, 256, 256, 32)    9216        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (1, 128, 128, 64)    256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (1, 64, 64, 128)     0           batch_normalization_59[0][0]     \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (1, 256, 256, 32)    128         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (1, 128, 128, 64)    0           batch_normalization_51[0][0]     \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (1, 64, 64, 128)     0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (1, 256, 256, 32)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (1, 128, 128, 64)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (1, 64, 64, 128)     147456      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (1, 256, 256, 32)    9216        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (1, 128, 128, 64)    36864       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (1, 64, 64, 128)     512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (1, 256, 256, 32)    128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (1, 128, 128, 64)    256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (1, 64, 64, 128)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (1, 256, 256, 32)    0           batch_normalization_45[0][0]     \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (1, 128, 128, 64)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (1, 64, 64, 128)     147456      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (1, 256, 256, 32)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (1, 128, 128, 64)    36864       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (1, 64, 64, 128)     512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (1, 128, 128, 64)    256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (1, 64, 64, 128)     0           batch_normalization_61[0][0]     \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (1, 128, 128, 32)    9216        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (1, 128, 128, 64)    0           batch_normalization_53[0][0]     \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (1, 64, 64, 128)     0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (1, 128, 128, 32)    128         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (1, 128, 128, 64)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (1, 64, 64, 64)      8192        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (1, 128, 128, 32)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (1, 128, 128, 64)    18432       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (1, 64, 64, 64)      256         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (1, 64, 64, 128)     36864       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (1, 64, 64, 128)     73728       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (1, 128, 128, 64)    256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (1, 128, 128, 64)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (1, 64, 64, 128)     512         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (1, 64, 64, 128)     512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (1, 128, 128, 32)    2048        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (1, 64, 64, 32)      4096        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (1, 128, 128, 64)    0           batch_normalization_64[0][0]     \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (1, 64, 64, 128)     0           batch_normalization_67[0][0]     \n",
      "                                                                 batch_normalization_68[0][0]     \n",
      "                                                                 activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (1, 128, 128, 32)    128         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (1, 64, 64, 32)      128         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (1, 128, 128, 64)    36864       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (1, 64, 64, 128)     147456      add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (1, 32, 32, 256)     294912      add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (1, 256, 256, 32)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (1, 256, 256, 32)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (1, 128, 128, 64)    256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (1, 64, 64, 128)     512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (1, 32, 32, 256)     1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (1, 256, 256, 32)    0           activation_42[0][0]              \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (1, 128, 128, 64)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (1, 64, 64, 128)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (1, 32, 32, 256)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (1, 256, 256, 32)    9216        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (1, 128, 128, 64)    36864       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (1, 64, 64, 128)     147456      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (1, 32, 32, 256)     589824      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (1, 256, 256, 32)    128         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (1, 128, 128, 64)    256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (1, 64, 64, 128)     512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (1, 32, 32, 256)     1024        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (1, 256, 256, 32)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (1, 128, 128, 64)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (1, 64, 64, 128)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (1, 32, 32, 256)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (1, 256, 256, 32)    9216        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (1, 128, 128, 64)    36864       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (1, 64, 64, 128)     147456      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (1, 32, 32, 256)     589824      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (1, 256, 256, 32)    128         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (1, 128, 128, 64)    256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (1, 64, 64, 128)     512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (1, 32, 32, 256)     1024        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (1, 256, 256, 32)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (1, 128, 128, 64)    0           batch_normalization_82[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (1, 64, 64, 128)     0           batch_normalization_90[0][0]     \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (1, 32, 32, 256)     0           batch_normalization_98[0][0]     \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (1, 256, 256, 32)    9216        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (1, 128, 128, 64)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (1, 64, 64, 128)     0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (1, 32, 32, 256)     0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (1, 256, 256, 32)    128         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (1, 128, 128, 64)    36864       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (1, 64, 64, 128)     147456      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (1, 32, 32, 256)     589824      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (1, 256, 256, 32)    0           batch_normalization_74[0][0]     \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (1, 128, 128, 64)    256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (1, 64, 64, 128)     512         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (1, 32, 32, 256)     1024        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (1, 256, 256, 32)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (1, 128, 128, 64)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (1, 64, 64, 128)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (1, 32, 32, 256)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (1, 256, 256, 32)    9216        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (1, 128, 128, 64)    36864       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (1, 64, 64, 128)     147456      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (1, 32, 32, 256)     589824      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (1, 256, 256, 32)    128         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (1, 128, 128, 64)    256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (1, 64, 64, 128)     512         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (1, 32, 32, 256)     1024        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (1, 256, 256, 32)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (1, 128, 128, 64)    0           batch_normalization_84[0][0]     \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (1, 64, 64, 128)     0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (1, 32, 32, 256)     0           batch_normalization_100[0][0]    \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (1, 256, 256, 32)    9216        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (1, 128, 128, 64)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (1, 64, 64, 128)     0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (1, 32, 32, 256)     0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (1, 256, 256, 32)    128         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (1, 128, 128, 64)    36864       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (1, 64, 64, 128)     147456      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (1, 32, 32, 256)     589824      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (1, 256, 256, 32)    0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (1, 128, 128, 64)    256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (1, 64, 64, 128)     512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (1, 32, 32, 256)     1024        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (1, 256, 256, 32)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (1, 128, 128, 64)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (1, 64, 64, 128)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (1, 32, 32, 256)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (1, 256, 256, 32)    9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (1, 128, 128, 64)    36864       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (1, 64, 64, 128)     147456      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (1, 32, 32, 256)     589824      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (1, 256, 256, 32)    128         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (1, 128, 128, 64)    256         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (1, 64, 64, 128)     512         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (1, 32, 32, 256)     1024        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (1, 256, 256, 32)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (1, 128, 128, 64)    0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (1, 64, 64, 128)     0           batch_normalization_94[0][0]     \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (1, 32, 32, 256)     0           batch_normalization_102[0][0]    \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (1, 256, 256, 32)    9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (1, 128, 128, 64)    0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (1, 64, 64, 128)     0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (1, 32, 32, 256)     0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (1, 256, 256, 32)    128         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (1, 128, 128, 64)    36864       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (1, 64, 64, 128)     147456      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (1, 32, 32, 256)     589824      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (1, 256, 256, 32)    0           batch_normalization_78[0][0]     \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (1, 128, 128, 64)    256         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (1, 64, 64, 128)     512         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (1, 32, 32, 256)     1024        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (1, 256, 256, 32)    0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (1, 128, 128, 64)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (1, 64, 64, 128)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (1, 32, 32, 256)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (1, 256, 256, 32)    9216        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (1, 128, 128, 64)    36864       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (1, 64, 64, 128)     147456      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (1, 32, 32, 256)     589824      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (1, 256, 256, 32)    128         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (1, 128, 128, 64)    256         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (1, 64, 64, 128)     512         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (1, 32, 32, 256)     1024        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (1, 256, 256, 32)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (1, 128, 128, 64)    0           batch_normalization_88[0][0]     \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (1, 64, 64, 128)     0           batch_normalization_96[0][0]     \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (1, 32, 32, 256)     0           batch_normalization_104[0][0]    \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (1, 256, 256, 32)    9216        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (1, 128, 128, 64)    0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (1, 64, 64, 128)     0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (1, 32, 32, 256)     0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (1, 256, 256, 32)    128         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (1, 128, 128, 32)    2048        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (1, 64, 64, 32)      4096        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (1, 32, 32, 32)      8192        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (1, 256, 256, 32)    0           batch_normalization_80[0][0]     \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (1, 128, 128, 32)    128         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (1, 64, 64, 32)      128         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (1, 32, 32, 32)      128         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (1, 256, 256, 32)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (1, 256, 256, 32)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (1, 256, 256, 32)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (1, 256, 256, 32)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (1, 256, 256, 128)   0           activation_71[0][0]              \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (1, 512, 512, 128)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (1, 512, 512, 32)    4096        up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (1, 512, 512, 32)    128         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (1, 512, 512, 32)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (1, 512, 512, 5)     160         activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (1, 512, 512, 5)     20          conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Activation)     (1, 512, 512, 5)     0           batch_normalization_110[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 9,528,308\n",
      "Trainable params: 9,508,778\n",
      "Non-trainable params: 19,530\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6343, 3960, 2540, 9557, 168, 9068, 6525, 9199, 7703, 5285, 8141, 2817, 8712, 7562, 10050, 3429, 2151, 4364, 8229, 6207, 655, 149, 5927, 4398, 5830, 5544, 10193, 3916, 6145, 4964, 9351, 3331, 3422, 9508, 8151, 9477, 1948, 9978, 2274, 3189, 7413, 8356, 1042, 6667, 6832, 8400, 8958, 6130, 6448, 2857, 7993, 2720, 9918, 1774, 260, 8549, 2975, 685, 352, 2266, 2516, 8432, 7701, 7311, 546, 1531, 5938, 3078, 7609, 9323, 5181, 9963, 5894, 5701, 1962, 5764, 4859, 3449, 9246, 396, 2330, 10043, 3538, 4643, 3864, 4020, 7935, 8647, 3461, 3360, 612, 4435, 3762, 3393, 4253, 3448, 6205, 1960, 4824, 5670, 10166, 2362, 4086, 3937, 8989, 8986, 495, 7003, 2106, 8679, 5598, 2287, 1652, 2382, 2402, 2276, 9939, 1465, 1137, 403, 7187, 348, 7425, 1443, 6071, 6506, 446, 9003, 3138, 3798, 2749, 1702, 3571, 2775, 2634, 7040, 1155, 1074, 9093, 1744, 4344, 3745, 8279, 4733, 8193, 2198, 5997, 2750, 1809, 9319, 4065, 2656, 1999, 4869, 6700, 3016, 8462, 7079, 2531, 8457, 6164, 1823, 876, 9046, 9151, 4145, 6822, 6753, 135, 4770, 798, 9536, 5757, 6572, 2064, 4919, 5832, 5000, 8858, 8612, 1409, 9977, 6215, 1878, 3255, 5705, 8945, 7797, 2830, 5274, 8671, 8563, 4309, 4481, 3288, 9201, 8304, 7099, 4494, 4986, 5449, 8505, 2608, 8363, 4023, 4042, 8453, 7547, 384, 4748, 3909, 2763, 325, 1877, 229, 821, 6278, 4903, 6888, 1659, 1635, 7090, 9041, 3367, 7640, 9284, 5703, 6531, 6720, 5430, 3185, 2074, 678, 5886, 4745, 153, 3250, 4728, 8537, 8361, 3180, 2941, 5219, 4308, 4174, 9864, 4803, 294, 8303, 3296, 5492, 8697, 7910, 8128, 9221, 6304, 5245, 4888, 8968, 4618, 5998, 8030, 6790, 3192, 3462, 4698, 8343, 7312, 9407, 3539, 8252, 744, 3096, 5908, 453, 5401, 2073, 3784, 8912, 1489, 2614, 8844, 1065, 6382, 2405, 776, 7226, 5978, 1185, 8205, 9655, 10095, 7098, 3953, 4673, 10059, 7291, 6339, 8146, 4179, 9437, 395, 6073, 4215, 2995, 3396, 6344, 4628, 8709, 3855, 2169, 6633, 5616, 3391, 1021, 6355, 1534, 1799, 9387, 1603, 5214, 7550, 10002, 3562, 2790, 8069, 3502, 8289, 2429, 4185, 8202, 8601, 8195, 5905, 6020, 8119, 3969, 7302, 9334, 740, 3901, 6755, 5374, 8530, 2269, 3411, 312, 1318, 1921, 1222, 9281, 6175, 8155, 5610, 819, 8393, 6703, 7731, 5753, 9471, 3780, 2862, 7173, 9509, 5120, 8547, 7411, 8911, 3683, 8136, 7534, 3190, 8024, 9459, 6358, 8813, 1891, 5554, 7887, 2433, 6924, 6062, 8775, 2728, 6242, 6662, 8544, 74, 5751, 10142, 7678, 1701, 7076, 9385, 1951, 4014, 5324, 6910, 1640, 7419, 8222, 5586, 3575, 1841, 5033, 387, 9468, 6757, 1452, 7412, 7169, 2570, 7314, 7368, 4924, 1355, 1520, 9886, 4110, 7117, 8943, 4837, 6839, 838, 9598, 9456, 933, 9134, 433, 7952, 4165, 7118, 6340, 9, 7558, 6403, 3673, 6183, 10067, 5003, 3586, 10022, 7233, 2829, 6986, 5504, 2565, 4305, 4085, 10039, 904, 8008, 578, 7131, 3619, 9429, 3226, 277, 5196, 9728, 3552, 597, 9278, 576, 9008, 79, 5593, 9047, 223, 3464, 3732, 6438, 8885, 6229, 152, 1591, 7230, 2499, 2234, 9078, 1798, 1638, 5010, 3721, 2767, 963, 1239, 7795, 4917, 8316, 5280, 9506, 9072, 5417, 3000, 4982, 3280, 1111, 1316, 5931, 6661, 1257, 2130, 643, 9300, 1686, 8249, 1214, 8416, 12, 8725, 7505, 1116, 9932, 8270, 7429, 5184, 2861, 3112, 9972, 3373, 4343, 6920, 8213, 3043, 8879, 5924, 5713, 1189, 2937, 9230, 5795, 4152, 10133, 7105, 1411, 6563, 1567, 2203, 5016, 3176, 3218, 2208, 6840, 2216, 5841, 7920, 1830, 7861, 5040, 9347, 1127, 2508, 5879, 4284, 4203, 1667, 6719, 6844, 10163, 227, 2056, 5494, 7408, 143, 7936, 5021, 8619, 3977, 2411, 2930, 808, 9107, 5552, 4299, 6805, 6480, 5543, 3131, 2514, 3652, 5097, 8824, 2186, 2682, 18, 2903, 3829, 536, 1303, 4449, 7397, 3390, 9702, 1406, 9851, 3691, 561, 9924, 8194, 4075, 8470, 7575, 10143, 5660, 8967, 3325, 426, 1150, 1158, 7924, 6488, 1575, 4718, 2014, 8351, 3097, 6761, 9130, 3882, 6627, 5805, 247, 4744, 2751, 9318, 3431, 5821, 4233, 3763, 816, 6313, 6555, 3914, 7783, 10098, 2594, 3370, 6452, 2241, 473, 804, 7905, 2438, 580, 3624, 3401, 9556, 4811, 123, 7537, 2488, 3810, 5532, 4813, 4467, 8278, 9550, 3281, 3912, 2045, 1459, 9116, 9249, 3277, 2506, 6583, 7257, 65, 4397, 1061, 8639, 7733, 9443, 1486, 8234, 5246, 5815, 9648, 9132, 103, 8950, 1311, 6473, 5404, 9757, 4225, 2339, 390, 1661, 3723, 9018, 3681, 6361, 4140, 3765, 4702, 2893, 673, 8212, 3511, 4663, 5490, 1754, 7620, 7171, 3026, 7947, 7846, 6558, 589, 358, 2739, 585, 5837, 9366, 5036, 9968, 6595, 7441, 3532, 4157, 892, 9814, 3703, 518, 3567, 9125, 6296, 3948, 5891, 3135, 4679, 4273, 7577, 1708, 1069, 8088, 5273, 8324, 5755, 5199, 264, 6022, 8939, 7610, 7744, 2581, 8048, 7372, 8273, 4848, 4585, 10109, 6594, 6942, 1115, 3345, 8835, 7944, 9645, 7055, 7867, 279, 6500, 425, 736, 9104, 2645, 7493, 7194, 3332, 686, 6570, 5212, 9033, 2561, 4186, 2031, 8676, 7751, 10136, 8206, 2948, 7729, 1315, 7052, 8345, 6457, 7009, 6649, 2097, 7705, 4426, 2400, 1478, 1362, 6542, 1020, 2137, 5573, 1153, 4063, 9333, 8931, 1995, 4908, 3842, 9795, 2639, 2626, 4579, 710, 3446, 2063, 2249, 6874, 7283, 4163, 10060, 6393, 3010, 1010, 2697, 9052, 2194, 8643, 7292, 7572, 7200, 3955, 4381, 1653, 7930, 1988, 6060, 1293, 10020, 2457, 8264, 2609, 2112, 4358, 6222, 1726, 1348, 2782, 7438, 5002, 8100, 3743, 310, 268, 860, 8101, 10194, 6014, 7625, 3715, 6732, 8908, 4172, 391, 2532, 96, 9878, 5747, 4715, 5988, 8728, 2883, 9117, 5482, 3684, 6740, 718, 6992, 3965, 3896, 6894, 7872, 7439, 6837, 9405, 2306, 6760, 7433, 1014, 1195, 7386, 8794, 9916, 1347, 9682, 2147, 4491, 2661, 5768, 3665, 1736, 3213, 7258, 2455, 4234, 1832, 9342, 6964, 7225, 8737, 7282, 9698, 8374, 5839, 1167, 5226, 1812, 5411, 454, 3120, 8520, 1570, 9442, 76, 7158, 5844, 3199, 2858, 10102, 10076, 4041, 4143, 7721, 2459, 9211, 383, 7796, 4125, 8447, 46, 9488, 7864, 10019, 2283, 6739, 8287, 7825, 3040, 2490, 858, 8360, 3682, 5487, 704, 601, 1242, 3095, 8241, 6039, 682, 4587, 925, 834, 7092, 10025, 44, 2833, 4370, 2533, 482, 1990, 8881, 2103, 2600, 6520, 9872, 2435, 7065, 3205, 6694, 6298, 6682, 2412, 7616, 94, 7186, 5893, 3418, 9062, 613, 341, 3126, 2713, 8956, 5236, 9112, 1488, 571, 8282, 2471, 6764, 9189, 3963, 3318, 9450, 6904, 1141, 8189, 5547, 2631, 4502, 4022, 3128, 8384, 2978, 3491, 9092, 6982, 125, 4402, 4799, 2373, 4781, 6013, 9497, 588, 10024, 3022, 9504, 2270, 6324, 3638, 870, 1683, 6364, 2588, 9090, 7402, 7615, 2166, 10006, 1055, 8805, 1957, 1989, 5836, 8706, 7893, 8776, 2170, 3136, 4047, 5572, 7539, 6153, 1894, 4949, 5910, 7011, 3415, 1596, 5254, 4573, 237, 2812, 4909, 8664, 8242, 2839, 357, 9554, 6018, 785, 1801, 82, 2679, 19, 3894, 4192, 273, 4815, 4365, 4854, 3544, 6544, 8158, 4591, 8991, 6237, 7000, 6374, 9612, 6160, 3927, 6776, 7870, 959, 10151, 5985, 7519, 4987, 9679, 6630, 7520, 7863, 4443, 8596, 1673, 3306, 4537, 2821, 233, 7831, 3001, 7836, 5427, 3244, 3778, 244, 5896, 2649, 4493, 9710, 5366, 1088, 968, 5953, 8850, 741, 6870, 9621, 3468, 6285, 6254, 7205, 1413, 8513, 10001, 3506, 4540, 2357, 8865, 3854, 1684, 2890, 958, 6800, 50, 3188, 1913, 102, 5580, 10158, 9308, 669, 9665, 761, 8061, 1129, 3936, 2677, 1499, 5615, 7808, 10165, 9941, 4345, 1335, 6453, 720, 4648, 10153, 3564, 2239, 3030, 2126, 4160, 7220, 3833, 3077, 7337, 5252, 10171, 9242, 1156, 3587, 5253, 8113, 4383, 4864, 2915, 4413, 375, 5239, 1113, 3177, 1763, 2134, 5516, 2541, 9439, 1147, 9818, 6194, 2699, 5291, 6485, 9228, 5195, 2524, 6267, 5309, 2849, 1660, 9859, 6601, 6228, 2619, 5814, 5293, 3923, 6862, 9492, 4013, 4507, 2873, 7023, 5408, 7211, 8603, 2434, 7737, 3253, 10035, 2365, 2501, 37, 3959, 7195, 249, 3155, 4404, 6834, 9381, 8310, 7971, 7775, 897, 8791, 7139, 2616, 7051, 3437, 7018, 9361, 1212, 4079, 9711, 5151, 3767, 4646, 1738, 5488, 2264, 2737, 7981, 5457, 4958, 8796, 8297, 900, 1251, 7247, 1334, 7299, 7871, 3554, 7679, 448, 5519, 8349, 6019, 1835, 8973, 2344, 8352, 8256, 4762, 3633, 118, 8261, 2101, 6381, 3823, 631, 9891, 537, 6637, 7166, 9577, 5721, 7694, 1161, 4298, 2003, 5220, 9015, 4474, 4400, 4196, 418, 6617, 7581, 130, 3260, 6998, 1187, 3666, 191, 3492, 8238, 2047, 7179, 5725, 6163, 923, 305, 5960, 3417, 7449, 1039, 4043, 3163, 9653, 7172, 2007, 8329, 9238, 8632, 7886, 2687, 6486, 7113, 869, 9288, 7856, 10005, 9996, 5982, 4835, 7892, 4256, 5612, 4236, 5231, 5649, 5331, 6151, 8736, 422, 4190, 3044, 2977, 3874, 2370, 5846, 2378, 7239, 3547, 6930, 4012, 7421, 927, 1984, 3900, 1897, 9976, 9312, 5194, 6887, 7997, 3550, 6972, 4731, 6641, 6173, 1881, 3017, 3609, 8678, 7068, 8818, 1820, 931, 6309, 5105, 6597, 1634, 5169, 7651, 1636, 8341, 4455, 4081, 2271, 803, 715, 7477, 5133, 8734, 5565, 3080, 2703, 4794, 5892, 9974, 2959, 3321, 5872, 3024, 1563, 3179, 747, 9532, 7907, 6376, 5884, 6950, 6057, 5899, 7663, 2268, 6276, 1170, 1498, 4342, 4771, 6392, 5852, 8930, 1783, 1539, 3929, 1583, 4452, 309, 3115, 4501, 1132, 618, 955, 4436, 4916, 4926, 8452, 1405, 6099, 3098, 10036, 6101, 255, 9337, 5353, 827, 9155, 1679, 4061, 2758, 9671, 3338, 7338, 6931, 4227, 4932, 3536, 9191, 6407, 9890, 4303, 3507, 9526, 6647, 6866, 2964, 658, 8044, 9875, 8606, 2613, 7724, 9486, 5763, 6592, 6841, 6421, 5512, 1768, 10071, 6727, 5383, 7203, 2905, 8577, 8038, 5294, 7658, 1847, 5570, 4307, 1442, 6223, 8501, 8938, 3436, 5681, 7707, 9778, 1211, 2075, 6777, 5708, 7071, 4118, 7718, 3290, 1822, 7913, 1749, 6523, 5301, 6903, 7351, 366, 10074, 3615, 3950, 3740, 5922, 8153, 1530, 3791, 6907, 308, 902, 3678, 7538, 4060, 7908, 2043, 4267, 4202, 835, 8566, 4706, 7708, 5187, 5596, 6468, 9541, 9730, 532, 2381, 732, 6809, 2799, 5311, 3672, 8695, 7080, 8078, 3182, 3800, 4367, 4843, 1971, 6391, 6055, 5916, 2322, 5877, 7346, 6225, 9356, 2972, 4863, 4418, 2828, 6307, 4810, 6970, 1191, 7986, 9555, 3359, 5522, 8243, 1588, 10092, 7374, 10062, 1180, 3999, 1103, 9988, 175, 9418, 667, 52, 2197, 3127, 5074, 788, 5521, 8342, 1860, 7420, 1514, 2597, 6097, 9415, 451, 9440, 8085, 6335, 8244, 55, 5032, 6501, 5399, 939, 9751, 2067, 9920, 6857, 8690, 4030, 5731, 2082, 7613, 4221, 8321, 2232, 8376, 7785, 6737, 8259, 5217, 7289, 1556, 261, 6640, 4461, 3869, 8716, 7596, 2691, 9635, 7635, 3358, 7770, 458, 1734, 6028, 9430, 6481, 9120, 1569, 3662, 8541, 5337, 1053, 3776, 8214, 7246, 22, 2195, 8477, 2089, 5084, 3025, 10191, 4623, 1888, 10070, 1219, 471, 3058, 8531, 5382, 4995, 4198, 7512, 1532, 6442, 9038, 4319, 793, 2009, 3311, 9048, 6919, 2800, 8756, 2414, 4580, 9414, 9564, 6471, 7670, 360, 9954, 8145, 7015, 126, 4660, 6941, 9133, 491, 4601, 3508, 3303, 289, 4349, 8770, 1979, 9722, 5330, 4244, 2723, 1024, 8486, 2689, 9868, 1058, 1907, 1969, 8652, 1388, 3906, 1084, 8966, 6437, 3121, 7188, 6799, 4136, 9673, 4572, 1091, 385, 8064, 9371, 1201, 6724, 4553, 5855, 3470, 1217, 7934, 2706, 1600, 5624, 9083, 7535, 9725, 4753, 3231, 4138, 8236, 8040, 6947, 7953, 2525, 2579, 5304, 7987, 7097, 2117, 452, 1688, 1695, 4139, 1821, 7177, 1223, 6631, 7108, 5342, 9402, 5669, 1784, 216, 924, 4380, 9870, 2898, 9896, 3944, 1245, 1571, 8396, 3669, 3050, 8630, 1578, 6036, 9531, 9969, 160, 2289, 9103, 1401, 7868, 1615, 1677, 8371, 5563, 7958, 7994, 4006, 9769, 405, 6026, 8200, 6423, 1244, 9990, 1855, 2760, 4966, 7666, 9917, 8764, 6868, 8988, 6417, 2182, 322, 3760, 6515, 5202, 5506, 2624, 2816, 7392, 9680, 9419, 2386, 3591, 5433, 6539, 2986, 1444, 10097, 9883, 5674, 1762, 7928, 2989, 1525, 9853, 9965, 6226, 4929, 9192, 469, 42, 6537, 8111, 8225, 9773, 9328, 4998, 5604, 625, 9589, 1470, 8593, 8872, 5093, 2879, 4333, 4952, 4983, 2836, 5530, 3891, 1787, 459, 4059, 9670, 5371, 388, 114, 7802, 5186, 6234, 1122, 5583, 5539, 456, 3509, 942, 4111, 2280, 1120, 8936, 574, 5057, 9216, 5507, 4389, 705, 4480, 1826, 2886, 1611, 2644, 3935, 9975, 8418, 7033, 4547, 749, 7325, 6499, 7897, 3852, 2864, 8348, 1079, 4378, 8050, 6769, 8469, 4503, 386, 3928, 1628, 5739, 4067, 3346, 4252, 7217, 1527, 5715, 1302, 3424, 5868, 3060, 1427, 2453, 2464, 4851, 9559, 5995, 2356, 5588, 3, 9099, 8488, 7407, 10173, 6513, 9933, 5232, 5421, 406, 8137, 466, 9376, 586, 7852, 111, 8250, 2998, 610, 2475, 9561, 4732, 640, 6797, 8928, 7471, 2252, 6425, 9737, 918, 9213, 494, 6756, 7595, 1445, 4199, 106, 5594, 624, 10117, 4820, 8782, 4630, 5842, 5790, 8798, 6867, 888, 173, 1255, 2246, 4672, 6260, 5007, 6974, 2368, 1943, 177, 2538, 7234, 7527, 7272, 4395, 6346, 4301, 1795, 461, 7182, 5215, 4376, 4338, 2920, 10174, 4913, 165, 8605, 3884, 830, 5648, 1090, 9922, 3946, 750, 3104, 4339, 8767, 7199, 8108, 324, 5365, 7122, 2952, 4636, 7738, 1472, 8121, 3700, 278, 6952, 53, 9834, 257, 2946, 4895, 1959, 1017, 5026, 3513, 9601, 7684, 6295, 5825, 10186, 2299, 3668, 6384, 6251, 3130, 1524, 3283, 8228, 1845, 8326, 893, 4231, 8065, 8079, 9705, 9094, 6265, 2715, 2856, 1617, 8521, 6263, 1317, 4177, 2237, 2754, 8636, 7026, 465, 717, 6283, 8689, 8507, 3011, 6235, 2174, 4590, 9071, 1448, 4479, 2393, 5968, 7442, 5463, 9654, 5423, 5149, 8407, 9780, 5524, 806, 32, 1687, 5758, 6569, 4122, 4578, 7435, 9540, 2108, 7490, 5140, 7926, 4827, 3268, 8272, 2328, 1632, 8629, 993, 3731, 2934, 4328, 4218, 7045, 584, 1171, 1678, 9732, 9179, 7592, 8680, 2983, 2746, 5224, 9224, 4755, 7834, 4324, 5576, 7294, 9110, 4408, 9156, 2065, 9517, 4534, 10051, 4769, 7107, 5849, 6380, 3910, 4882, 6124, 10094, 1642, 92, 1290, 8131, 1778, 5271, 6120, 121, 6261, 6925, 2914, 3362, 1254, 570, 5773, 8001, 8378, 35, 702, 6390, 2240, 9901, 6814, 7815, 4312, 3410, 4992, 2511, 9771, 1516, 5575, 1940, 2068, 7287, 2315, 10068, 10150, 3341, 642, 2669, 7360, 896, 1566, 10187, 9218, 3617, 2834, 5030, 5092, 81, 434, 2653, 8738, 4183, 8668, 9862, 8960, 8187, 9827, 5454, 3298, 4211, 8923, 2667, 9007, 1871, 8177, 6615, 1865, 5028, 7676, 1052, 1235, 8260, 7031, 8516, 4805, 3680, 7697, 4078, 6638, 905, 7877, 9959, 204, 7330, 8620, 84, 8853, 8190, 9684, 801, 7235, 3578, 1297, 2260, 359, 9709, 6269, 7451, 7972, 9838, 4405, 4538, 186, 6116, 1612, 6642, 3349, 1607, 3903, 9611, 5699, 5599, 4028, 5961, 5939, 2586, 5973, 8081, 2172, 5414, 1740, 10056, 6092, 789, 2058, 1680, 5538, 6253, 5117, 6010, 2385, 965, 9423, 742, 1598, 5362, 5039, 5247, 5127, 1815, 5420, 8510, 5505, 664, 7650, 1146, 10182, 3133, 346, 5321, 4261, 10078, 5174, 9113, 9123, 5943, 6655, 9781, 4034, 1338, 3200, 9793, 5932, 1173, 487, 314, 6211, 4100, 3845, 5958, 3881, 784, 5860, 5234, 6951, 2596, 5318, 4940, 2305, 9186, 9341, 3841, 1725, 6660, 9774, 9089, 6552, 4099, 6676, 3610, 2568, 8822, 2807, 56, 6447, 739, 9362, 699, 9622, 2118, 75, 9957, 1540, 4676, 3161, 10021, 7794, 4514, 1045, 609, 9967, 5957, 8322, 7279, 5413, 1672, 5533, 13, 3635, 7755, 1204, 9136, 1275, 916, 1906, 3913, 8170, 3493, 1727, 8353, 6792, 5726, 3400, 772, 9302, 1560, 9826, 2404, 5614, 1495, 190, 2491, 7231, 1114, 6291, 9736, 2399, 7728, 9527, 243, 1200, 1421, 3452, 8921, 3184, 2984, 6669, 7967, 313, 6987, 7837, 3599, 5796, 3125, 2022, 9234, 9344, 5354, 4310, 5270, 8355, 3782, 4361, 7984, 6193, 5784, 1737, 950, 4737, 7919, 9457, 1387, 7643, 6025, 9758, 7639, 6796, 5443, 7845, 9126, 2793, 8927, 1862, 8185, 7812, 3392, 2733, 10160, 3068, 5314, 3369, 5450, 7977, 3175, 2701, 4524, 9173, 8534, 7094, 4874, 799, 2509, 10137, 8368, 3722, 8424, 6131, 333, 7698, 7249, 6436, 8159, 6923, 2559, 1389, 3235, 3593, 8747, 230, 3568, 7469, 6414, 9233, 1107, 10190, 415, 9505, 5553, 7906, 4694, 2818, 1484, 2685, 5702, 6697, 5090, 6360, 239, 3408, 783, 2666, 7819, 4144, 7726, 1747, 8815, 7777, 9854, 6993, 4135, 7793, 7010, 9593, 1238, 696, 7388, 8773, 1513, 5019, 8439, 7038, 2676, 5136, 5947, 7140, 6387, 4678, 5083, 7851, 5619, 8842, 7975, 1885, 483, 9995, 551, 5014, 6929, 727, 7221, 5898, 1817, 9102, 2363, 9012, 141, 7496, 6711, 1447, 3729, 8784, 7633, 7208, 3548, 5882, 484, 4763, 8473, 2745, 4907, 9101, 2422, 5859, 6415, 6936, 4064, 683, 4518, 5048, 8934, 8015, 4683, 9744, 8134, 4991, 2351, 9839, 4879, 203, 3203, 7280, 7472, 7675, 2721, 3504, 6802, 1208, 4866, 8498, 5820, 3750, 7847, 6350, 8086, 276, 10176, 72, 8292, 4976, 3518, 1889, 3425, 5409, 10045, 5419, 3651, 4120, 2987, 3774, 8924, 8482, 9307, 10014, 4302, 5902, 3497, 4915, 8656, 4327, 921, 9100, 4101, 258, 753, 195, 8254, 7087, 8391, 3695, 6478, 8132, 6156, 1780, 818, 6056, 1060, 6143, 3295, 531, 1772, 10023, 9406, 3627, 154, 7232, 6507, 7866, 9503, 6319, 4839, 2980, 7874, 3246, 7788, 1850, 8836, 3697, 1573, 4897, 475, 5154, 430, 4654, 4473, 573, 2966, 1923, 9275, 4320, 8308, 550, 8715, 2265, 4465, 5840, 1119, 2529, 91, 672, 3402, 3219, 427, 8314, 5989, 774, 6696, 8613, 6032, 5161, 5111, 8106, 7319, 5126, 1123, 10175, 3458, 4329, 2358, 549, 2479, 2294, 2940, 8760, 1924, 5561, 3679, 6810, 3744, 6580, 6519, 1711, 5853, 5813, 8628, 9085, 2902, 2150, 6738, 8785, 3931, 5620, 2982, 1152, 6038, 1041, 3432, 6367, 9686, 4904, 4511, 7533, 7047, 477, 7152, 3569, 3005, 9137, 9578, 6431, 7507, 6709, 679, 2243, 7875, 9297, 557, 1716, 10134, 86, 4200, 1349, 3222, 2171, 4128, 9514, 29, 8588, 355, 9264, 4097, 4036, 7637, 7838, 3405, 614, 7313, 633, 457, 2025, 1506, 9863, 2048, 3922, 9065, 2183, 10159, 6648, 6178, 6366, 3247, 1526, 7297, 2939, 8903, 8655, 2038, 8586, 7578, 5053, 5098, 6494, 8087, 3631, 6440, 2625, 6113, 374, 7016, 8906, 5760, 5316, 8692, 4555, 505, 3957, 5110, 1353, 9098, 8726, 1228, 6002, 8248, 7310, 1647, 7466, 1304, 5517, 6218, 6914, 8871, 6203, 2428, 7432, 70, 538, 10118, 6477, 3542, 3122, 7689, 837, 140, 3197, 4546, 8786, 706, 1206, 4257, 7468, 3699, 8714, 6012, 2292, 21, 6093, 634, 2359, 3630, 4717, 6368, 5237, 6699, 5545, 6675, 7242, 6058, 5286, 6208, 7321, 7084, 8165, 7827, 4055, 6053, 2354, 8315, 4259, 3862, 1994, 1261, 10016, 7448, 7965, 4801, 5005, 10063, 1441, 7821, 9991, 9770, 2168, 1900, 3757, 7034, 4146, 9057, 5152, 9017, 3939, 6426, 438, 7209, 7136, 4610, 3158, 1420, 8408, 3877, 4703, 5242, 10003, 8740, 9465, 794, 1619, 1182, 1283, 7365, 7315, 9390, 7444, 2865, 2055, 3998, 654, 1663, 7250, 8319, 8821, 3198, 3379, 8027, 1234, 3643, 9881, 8414, 5020, 6372, 8494, 3302, 1510, 7996, 569, 2603, 5300, 3023, 1043, 5077, 7248, 10138, 9329, 5131, 5592, 1908, 9106, 5909, 9432, 3487, 9608, 4052, 8428, 777, 1324, 3036, 6259, 1232, 8754, 7753, 9979, 6129, 8535, 7473, 6762, 8196, 421, 7566, 6898, 7593, 973, 3598, 2079, 8127, 5145, 5585, 509, 3377, 2178, 6793, 8917, 5216, 7653, 9207, 6725, 1458, 8559, 7776, 3972, 6328, 4266, 9364, 9175, 9950, 1047, 2442, 2335, 773, 8581, 9573, 8135, 2403, 7792, 7585, 4808, 490, 8350, 5627, 9810, 1456, 9768, 5499, 5439, 1270, 865, 1048, 10129, 4193, 8571, 1062, 7486, 4153, 4833, 5626, 7281, 8793, 8570, 5693, 5952, 3545, 180, 7085, 828, 7288, 48, 6691, 10177, 9575, 2945, 4001, 9885, 2450, 4972, 929, 9388, 3266, 632, 328, 9338, 4223, 10126, 7395, 5315, 3046, 5831, 4606, 3540, 9669, 138, 6551, 5387, 4129, 2421, 4516, 6184, 7101, 2932, 2583, 9084, 8002, 3381, 4529, 4458, 7654, 7931, 2034, 2990, 2180, 2665, 7543, 2690, 936, 5550, 6807, 3592, 2427, 871, 3647, 9910, 7183, 97, 6701, 9236, 1876, 9115, 5380, 9823, 4109, 6795, 1393, 5346, 4651, 5109, 922, 5485, 4571, 10183, 1819, 6491, 6538, 2128, 4761, 6249, 8398, 311, 3657, 8625, 200, 2248, 2039, 6713, 9966, 8149, 8247, 4693, 5803, 9739, 2278, 8808, 4564, 7891, 218, 1751, 823, 5718, 6146, 7109, 9719, 3065, 1276, 2928, 2719, 9756, 6027, 9602, 8545, 4550, 472, 3139, 10169, 3441, 3085, 6845, 2672, 6999, 1386, 4599, 615, 6673, 4738, 3234, 9413, 3985, 7025, 9367, 3856, 5520, 2161, 620, 4934, 8922, 7156, 6576, 5557, 5062, 87, 2040, 9937, 8463, 3558, 2086, 7137, 3766, 8160, 7584, 293, 7260, 2230, 2888, 6195, 4840, 2152, 563, 9400, 7201, 8223, 2789, 16, 409, 3075, 4468, 1756, 9545, 9139, 9444, 9900, 5229, 9672, 1081, 8839, 7389, 4355, 8178, 3416, 401, 5121, 4752, 1963, 8425, 5489, 5748, 6748, 8552, 4124, 8076, 8011, 9355, 6181, 6396, 3595, 4147, 1882, 8944, 2576, 746, 4069, 6758, 9445, 5094, 603, 3051, 4510, 8429, 6908, 4853, 8018, 635, 2698, 2021, 8667, 5107, 8023, 4237, 3967, 5071, 5972, 8339, 54, 3361, 6997, 8240, 3814, 3873, 5667, 2985, 6529, 5022, 8779, 8096, 5690, 5160, 8448, 5085, 3482, 7127, 9944, 4119, 1760, 3433, 1639, 164, 6338, 9263, 7889, 7014, 7067, 7266, 221, 7295, 398, 7854, 2423, 9765, 8925, 9865, 5568, 6599, 4506, 9946, 6424, 1814, 676, 2804, 3495, 3315, 6928, 8937, 5823, 944, 7784, 3649, 7876, 8974, 2233, 4812, 5911, 269, 8517, 167, 5987, 3987, 9843, 4902, 399, 4517, 972, 4631, 8864, 3186, 9074, 1917, 7756, 6104, 7387, 9279, 2965, 3335, 8285, 5878, 9231, 4608, 914, 7730, 3480, 1101, 4115, 8762, 393, 7004, 7545, 8014, 6450, 8219, 6596, 6575, 8795, 4098, 1507, 1644, 411, 8787, 4814, 7308, 8749, 1840, 1728, 8730, 4058, 5303, 4131, 1077, 6209, 2867, 1431, 2329, 8971, 4900, 2042, 10042, 7739, 1536, 368, 5691, 6482, 104, 2418, 259, 9867, 7555, 5445, 854, 9664, 3084, 6652, 9695, 2599, 7298, 8143, 1151, 98, 447, 3374, 3083, 8485, 8774, 6046, 6716, 5431, 693, 5635, 3902, 3940, 1266, 4291, 4003, 987, 2503, 8387, 7285, 7798, 9949, 5646, 5008, 8431, 8392, 4033, 4114, 7677, 6126, 9396, 462, 9484, 7300, 1428, 4768, 5710, 2992, 4142, 2113, 2610, 8318, 4062, 7804, 8742, 7476, 1269, 5920, 8299, 6959, 2517, 1186, 8103, 6765, 7710, 5628, 7661, 1775, 7966, 8102, 492, 8744, 7167, 6427, 3438, 3061, 250, 8554, 8642, 7551, 7129, 5729, 797, 8536, 7709, 3450, 5001, 7431, 6933, 8859, 4545, 4542, 6072, 7042, 3584, 9121, 5828, 4432, 1289, 7475, 1476, 4993, 1121, 2876, 1287, 9688, 8543, 813, 6247, 189, 7128, 5241, 8694, 7354, 2286, 5438, 2109, 6553, 7322, 3694, 3637, 10, 913, 2092, 443, 1253, 9791, 3081, 2379, 1358, 1698, 3006, 5780, 8169, 2601, 2396, 6489, 6363, 5179, 4617, 2251, 4634, 4931, 10135, 6512, 5069, 2030, 9606, 1474, 4901, 4686, 4894, 2090, 9871, 1295, 5319, 4095, 7833, 9436, 5587, 4210, 8456, 5370, 5135, 5467, 344, 7704, 8306, 2493, 6125, 2409, 1086, 7006, 3671, 3056, 7261, 7568, 9743, 3594, 8239, 7989, 7816, 1998, 8915, 6726, 1106, 122, 6877, 6290, 1944, 1856, 2646, 3154, 404, 4710, 8718, 8768, 4707, 7687, 1650, 1523, 7760, 4430, 9516, 3254, 4593, 8298, 7532, 3698, 2311, 3878, 5711, 7990, 7440, 7657, 7484, 1739, 507, 7116, 5325, 1110, 9741, 9259, 6321, 7582, 6654, 8641, 7600, 1909, 822, 8180, 4729, 9313, 4870, 8461, 7767, 1092, 857, 7762, 71, 583, 1861, 2981, 6031, 1365, 5974, 3102, 3523, 7598, 5611, 3992, 9646, 8460, 9311, 7406, 5625, 8609, 4512, 7841, 3109, 890, 907, 8271, 8010, 3183, 5472, 5955, 9326, 4956, 8583, 2415, 9158, 6829, 5067, 5073, 4569, 1373, 1589, 3384, 8856, 291, 8658, 9067, 3863, 3463, 651, 1720, 1975, 5535, 4352, 3737, 1085, 408, 4783, 2907, 6198, 5794, 5101, 6781, 9232, 1926, 9799, 3141, 4871, 6299, 7149, 1987, 2759, 881, 3500, 202, 8478, 3971, 2332, 8301, 9177, 185, 6752, 7125, 148, 4638, 5651, 2859, 7100, 9097, 4576, 8949, 2895, 7255, 7345, 9122, 9747, 3101, 5045, 280, 2327, 2497, 194, 9270, 8, 6629, 2512, 287, 9520, 4567, 14, 8901, 9844, 4721, 7404, 1166, 703, 7364, 1722, 4011, 7573, 3194, 9831, 4245, 9291, 6873, 9587, 8492, 1479, 4586, 5391, 8335, 9998, 1972, 9226, 6745, 863, 6770, 8493, 6128, 8300, 4357, 9227, 8451, 2773, 8197, 8978, 8479, 5683, 1154, 8933, 4446, 7627, 1139, 7961, 1018, 1502, 3932, 9206, 6348, 1594, 8699, 2272, 3654, 370, 636, 1064, 9353, 9815, 4251, 8557, 8157, 6083, 2081, 8902, 1905, 9696, 5801, 9530, 30, 5221, 567, 997, 4823, 6105, 6190, 2156, 7267, 9426, 1496, 6791, 887, 3409, 5889, 3543, 5263, 3505, 5709, 5940, 9157, 6189, 5495, 2316, 6554, 1697, 3908, 6052, 3519, 3372, 5994, 1920, 6487, 9639, 1952, 8662, 3241, 7430, 1246, 8999, 6171, 6279, 592, 6115, 4671, 2681, 9626, 4906, 1794, 4582, 7452, 895, 2569, 2819, 6995, 2615, 1337, 5261, 5462, 4642, 1224, 4288, 7384, 6212, 656, 4953, 4037, 4523, 6231, 6389, 1599, 10141, 3465, 1363, 6419, 5440, 2768, 8094, 10041, 6385, 1852, 5477, 3921, 3035, 5004, 4570, 1093, 6213, 9295, 7735, 2451, 590, 1544, 7725, 1733, 1267, 8434, 1221, 6744, 2869, 1375, 6490, 2196, 9599, 3459, 2943, 5446, 1109, 6906, 6536, 8262, 9552, 3233, 3835, 1508, 2301, 2420, 7048, 9713, 2448, 8880, 2380, 2036, 7980, 660, 4680, 1854, 4594, 9428, 2918, 2783, 10031, 745, 7630, 3772, 4979, 901, 1426, 2460, 4677, 6825, 1715, 7835, 6609, 8610, 6003, 5432, 7331, 162, 2526, 7035, 7992, 9572, 8302, 5740, 2309, 2602, 1301, 282, 2507, 9154, 5818, 3705, 8274, 1078, 3322, 782, 4439, 5782, 9077, 6869, 2346, 3041, 9292, 2752, 7165, 2255, 7669, 2855, 1453, 1168, 2220, 31, 371, 5266, 127, 3843, 9309, 7423, 725, 3693, 2050, 2622, 8291, 5712, 2295, 1867, 3071, 424, 6811, 1518, 7832, 3942, 2910, 3716, 9734, 8626, 8997, 6394, 5114, 7301, 6975, 10185, 1422, 9644, 2206, 691, 2466, 6182, 2407, 9962, 4091, 1643, 5811, 2394, 8669, 7114, 7803, 3658, 8275, 5735, 5471, 663, 762, 2781, 2023, 7692, 3319, 8181, 982, 5990, 8090, 1209, 9663, 4541, 7269, 3585, 2298, 7544, 4477, 2999, 5041, 5650, 4360, 4169, 521, 4379, 786, 3365, 9562, 6034, 6188, 771, 3563, 3378, 529, 7782, 2334, 7548, 2288, 5138, 4025, 7780, 2794, 3818, 10065, 6087, 8039, 7634, 619, 4317, 6557, 2757, 6818, 4331, 6729, 4875, 1340, 5706, 9726, 2539, 7682, 9687, 1417, 5289, 5904, 5359, 1919, 9010, 8068, 5192, 5046, 2225, 2416, 9637, 26, 8954, 1343, 4588, 147, 6819, 7624, 4950, 9037, 2076, 1927, 3636, 1899, 2872, 6068, 6446, 6135, 6170, 9162, 7263, 2210, 9118, 8199, 4175, 3221, 4222, 8616, 2027, 9204, 3831, 1761, 5191, 2753, 5829, 6949, 1954, 8327, 7428, 565, 2458, 10162, 4625, 8739, 8006, 4719, 8449, 8444, 7390, 9043, 7133, 3276, 2727, 3055, 6430, 9027, 7159, 5560, 2926, 1473, 2059, 3687, 8778, 5017, 1978, 4876, 1704, 1718, 10125, 3786, 2555, 4619, 4562, 1056, 1816, 1454, 1903, 6861, 3756, 6897, 188, 6827, 8843, 9749, 6418, 8980, 4102, 5013, 2884, 7422, 6533, 5435, 5299, 4487, 8894, 6405, 2744, 1051, 7671, 812, 8509, 6842, 4216, 6281, 5723, 2809, 5023, 1272, 8125, 8751, 9861, 6918, 214, 1577, 3430, 377, 10084, 3383, 5523, 3625, 8889, 9325, 920, 5869, 10090, 3363, 5119, 3590, 6996, 5903, 7659, 8276, 9147, 4270, 6287, 2462, 506, 4325, 508, 7161, 5965, 6459, 6541, 6180, 3320, 6817, 5356, 8763, 9689, 9634, 2267, 5479, 4559, 6707, 1806, 5484, 4437, 7450, 7485, 8611, 4861, 1332, 7145, 5156, 306, 1968, 7695, 5584, 7818, 5954, 525, 3821, 6356, 8977, 2473, 3840, 5746, 552, 5685, 3813, 6334, 8713, 2580, 3481, 6331, 1282, 8091, 7168, 9760, 7251, 6863, 9980, 3753, 6759, 9306, 7222, 9472, 2320, 6399, 3794, 9447, 5180, 6735, 6961, 2604, 3839, 3039, 9718, 5361, 6091, 9642, 738, 6879, 4826, 3958, 2138, 4241, 6616, 460, 3702, 6708, 7394, 856, 480, 6556, 9987, 3211, 2140, 3739, 1360, 3270, 1383, 1143, 8369, 1973, 2088, 129, 335, 5389, 307, 9960, 9250, 6534, 2593, 1023, 5791, 6137, 9403, 5054, 9820, 5714, 2005, 1144, 7964, 7373, 5789, 4807, 1609, 3758, 7464, 99, 6081, 7334, 3795, 7103, 7155, 2408, 9745, 4499, 3485, 9677, 8499, 6086, 4314, 8258, 5664, 2947, 5915, 8972, 8421, 4800, 3989, 6030, 1879, 7963, 9594, 8404, 4881, 2611, 3110, 7826, 2554, 9260, 9903, 7647, 5722, 3444, 5663, 5581, 3805, 6463, 7494, 4366, 4930, 5164, 5500, 9876, 8484, 4647, 3191, 8648, 3947, 7917, 3466, 7032, 3455, 9148, 7632, 5244, 1439, 5282, 954, 6273, 1843, 5788, 4323, 3876, 7549, 556, 6408, 7361, 10106, 8838, 3865, 5996, 809, 9662, 735, 8286, 9320, 5728, 5863, 7642, 4009, 755, 3796, 6937, 8080, 5843, 8665, 2741, 4482, 1649, 8338, 1808, 7341, 6715, 6330, 6320, 2595, 1515, 9824, 4611, 2675, 2096, 4957, 3853, 1551, 7399, 4994, 8105, 199, 8952, 9994, 146, 566, 7218, 6571, 5153, 4217, 6742, 3560, 2545, 805, 5011, 7688, 2756, 3727, 3655, 5632, 9491, 6270, 1016, 3583, 7786, 2285, 7597, 7064, 9647, 145, 708, 9144, 4260, 8635, 4000, 10080, 5887, 991, 297, 8748, 7656, 1385, 8526, 1950, 9193, 9340, 6293, 1554, 5617, 1026, 3350, 2154, 3783, 535, 6289, 9076, 9200, 4433, 3124, 2445, 4476, 9240, 5936, 3870, 7955, 4695, 1097, 4008, 6001, 4350, 5897, 996, 5155, 6988, 9474, 10040, 4943, 4955, 6398, 7526, 9036, 8870, 2489, 4627, 7160, 1398, 5372, 7943, 10087, 8375, 7237, 2387, 8120, 7515, 2684, 874, 8729, 4708, 6561, 5390, 6118, 1863, 3426, 3616, 7560, 3551, 9335, 3501, 3082, 5659, 4475, 7518, 340, 7503, 4212, 6628, 8004, 4774, 2658, 9483, 5502, 5096, 9897, 1555, 5856, 9779, 2374, 4340, 3171, 2740, 6074, 3088, 6600, 5095, 8168, 9912, 4793, 8166, 4412, 5975, 7881, 5415, 6621, 5787, 9521, 8803, 2925, 8653, 4795, 8325, 6849, 9629, 690, 9013, 1550, 7644, 3997, 476, 4668, 3007, 8053, 8590, 3229, 4335, 8743, 10061, 8897, 8022, 8947, 3445, 5452, 7190, 2762, 5012, 6008, 6668, 7988, 9905, 3851, 5367, 4469, 1902, 6567, 5076, 5049, 4496, 7339, 2970, 2548, 117, 1937, 647, 5113, 4528, 6088, 2149, 4575, 9409, 2598, 8969, 2813, 1793, 8685, 3885, 9022, 9194, 6865, 7636, 6492, 4164, 4739, 1227, 9392, 3457, 9363, 728, 4500, 909, 10122, 2078, 397, 8399, 3945, 956, 3187, 134, 2046, 4127, 5762, 1351, 10157, 7923, 9145, 7979, 10105, 9911, 1837, 2124, 7357, 1986, 7274, 4002, 6349, 3961, 351, 6210, 4264, 3570, 850, 790, 7414, 5329, 5338, 3117, 6985, 2426, 2377, 7355, 4282, 2235, 7022, 3792, 4318, 9529, 3267, 714, 2577, 2120, 2916, 8546, 659, 5655, 9395, 57, 3689, 4522, 593, 5558, 2498, 10054, 5227, 8873, 9735, 1503, 5091, 2899, 9752, 7746, 6704, 1407, 862, 3238, 2443, 6310, 6301, 8388, 4652, 4945, 6220, 9214, 8644, 8802, 1693, 8869, 8340, 1991, 8792, 1083, 6943, 8367, 9829, 9310, 5883, 3834, 4354, 2184, 7976, 4645, 7401, 1466, 10044, 9215, 1096, 8417, 9989, 7482, 5481, 8618, 582, 2188, 4855, 4765, 5292, 6774, 6483, 5200, 1831, 5148, 2343, 3803, 4384, 8389, 6875, 5137, 235, 4970, 3208, 716, 5778, 3911, 4159, 8312, 5061, 1450, 9571, 4374, 10139, 7467, 9522, 1183, 8347, 7278, 8854, 4561, 3890, 6133, 2996, 2803, 2705, 4644, 3094, 7968, 8251, 7521, 7711, 9023, 8057, 33, 4242, 441, 9565, 8904, 8092, 6288, 4471, 8161, 9500, 8405, 5378, 3264, 5977, 8771, 5465, 4132, 1961, 2474, 7720, 970, 8419, 9764, 6893, 7254, 9416, 2307, 528, 266, 6509, 3428, 811, 4723, 2582, 9499, 40, 4751, 3294, 7599, 1210, 652, 5190, 637, 906, 442, 6613, 2792, 2084, 6864, 5203, 1326, 8681, 3146, 1076, 9393, 5835, 6968, 9248, 2054, 10091, 2107, 1216, 2164, 6620, 10032, 3042, 4054, 93, 10116, 5249, 9898, 6804, 6357, 3148, 5305, 6429, 4942, 6327, 947, 9746, 2121, 10028, 9925, 8294, 1352, 9971, 2831, 209, 3549, 1271, 381, 373, 7787, 2144, 256, 9733, 4649, 859, 2696, 6325, 2710, 4451, 3272, 4536, 4088, 3420, 4566, 2222, 3454, 912, 9441, 4010, 2189, 3398, 8232, 5099, 3526, 4417, 353, 9075, 5527, 8783, 9466, 3357, 3054, 9255, 9763, 1929, 1057, 4817, 8891, 8696, 6736, 6503, 5124, 6397, 2087, 8026, 3994, 9956, 8013, 1511, 748, 3414, 3629, 3012, 4980, 5429, 1846, 9819, 6432, 7460, 5102, 7445, 176, 6741, 9640, 2587, 9879, 8406, 9809, 7191, 1707, 2221, 2553, 8698, 9798, 4885, 7426, 4639, 3279, 9378, 1743, 2472, 1181, 2352, 8575, 1834, 1766, 23, 4977, 304, 2969, 5971, 2024, 2091, 2736, 2454, 6021, 2049, 3646, 2326, 2037, 1800, 4999, 2469, 413, 9150, 5730, 4182, 1357, 10111, 2530, 4797, 5276, 5106, 7554, 3879, 6566, 7083, 2642, 6547, 3249, 5754, 6460, 1528, 10007, 3749, 8082, 9533, 1022, 8104, 688, 5697, 6162, 7223, 2797, 9042, 9821, 5923, 8383, 4505, 4004, 4933, 9339, 2798, 5410, 2523, 8265, 437, 8164, 9159, 3612, 301, 9379, 6464, 3134, 2778, 514, 1805, 1364, 7138, 7922, 7608, 5537, 8337, 6831, 6134, 1068, 7504, 9273, 1037, 1134, 3442, 3434, 709, 3718, 9481, 7662, 6665, 4602, 555, 2844, 5652, 5603, 7379, 4248, 2843, 3933, 2521, 2013, 7268, 2253, 6386, 9152, 2557, 7063, 3490, 9243, 1240, 5847, 8245, 9493, 8519, 8403, 1732, 5727, 1956, 5104, 1467, 1504, 5268, 9782, 5541, 8721, 1829, 4275, 4912, 1004, 7393, 5579, 8935, 2413, 1645, 2190, 1753, 543, 1264, 4390, 7410, 729, 758, 7252, 7362, 1007, 10179, 1341, 2779, 6730, 5743, 8814, 1376, 5510, 9055, 6294, 8918, 8527, 7328, 6252, 7036, 6059, 3734, 7683, 8704, 9410, 2960, 6994, 4415, 9060, 7120, 8089, 2020, 5345, 4074, 7396, 1713, 998, 5766, 980, 4336, 5865, 2430, 2318, 2536, 2026, 1292, 791, 4927, 9766, 513, 241, 5189, 3580, 8390, 2153, 769, 150, 9331, 3966, 3352, 402, 6614, 2730, 9641, 5243, 1789, 5262, 8409, 2162, 8402, 2605, 8055, 4922, 3930, 4112, 3057, 5396, 1788, 3274, 9583, 1641, 4105, 4089, 6510, 9659, 684, 1339, 6896, 1942, 6808, 3142, 8550, 7883, 5044, 3072, 3696, 9784, 5680, 9485, 2028, 2924, 1331, 9717, 2717, 1572, 2546, 7340, 7982, 6692, 3248, 3144, 9389, 9324, 1344, 6243, 3217, 879, 7256, 6127, 5875, 5700, 2011, 245, 1782, 9073, 9623, 768, 2558, 9706, 8385, 7779, 4300, 6636, 8354, 1742, 1868, 4777, 9569, 7453, 1610, 10161, 6878, 9701, 4187, 2229, 3027, 2303, 2802, 8000, 6607, 6106, 5496, 2461, 2492, 9149, 3049, 407, 6502, 695, 4049, 3129, 7681, 10170, 5929, 2547, 8556, 3093, 4427, 7437, 1992, 757, 4201, 3263, 9380, 6927, 9054, 3099, 489, 8394, 5925, 9195, 10017, 7541, 3905, 1105, 9775, 8817, 3262, 1400, 3535, 4155, 6167, 9668, 6504, 8896, 8627, 9185, 5658, 4206, 5355, 4925, 5034, 4981, 1003, 5809, 1605, 6443, 7115, 1977, 7112, 3178, 3860, 6152, 6785, 9096, 1770, 320, 2780, 7008, 763, 3074, 38, 3297, 644, 7326, 9282, 3956, 5967, 6565, 4743, 3168, 7563, 9187, 6017, 6317, 8226, 5503, 7674, 9142, 3299, 2218, 787, 775, 10069, 608, 4195, 3919, 764, 3066, 2277, 5250, 767, 1925, 3052, 594, 3801, 1160, 3872, 1259, 207, 4387, 6112, 3282, 1025, 6848, 5549, 8116, 7391, 1082, 8075, 435, 3836, 8789, 3820, 1359, 9172, 9462, 10079, 4641, 4667, 5369, 3804, 7918, 112, 5935, 10027, 2372, 9740, 3224, 5281, 9348, 6221, 2805, 7604, 7789, 6236, 9692, 8025, 1548, 9993, 1256, 284, 670, 9631, 3771, 722, 8594, 8028, 7890, 6853, 7790, 7949, 8373, 2465, 4440, 8150, 3846, 9951, 1192, 2204, 9370, 4846, 302, 10127, 7583, 6967, 7857, 4278, 3733, 85, 3770, 8465, 5343, 6763, 8828, 7723, 9417, 9178, 4990, 303, 626, 4704, 9708, 8112, 410, 9613, 4166, 4747, 8615, 9715, 5283, 2179, 3975, 943, 9346, 3704, 7110, 3527, 5448, 3667, 3525, 5150, 8745, 9095, 9268, 1493, 2297, 8898, 7150, 5696, 8126, 8837, 9816, 9128, 1199, 4674, 9135, 1073, 131, 9566, 4031, 2313, 671, 8735, 1063, 3447, 9183, 2923, 3859, 4887, 7434, 4290, 4029, 5442, 9588, 3529, 8054, 7070, 6219, 7509, 5623, 2016, 1803, 7262, 1440, 6983, 701, 5384, 9984, 5824, 3659, 1682, 5569, 2395, 8073, 1273, 4624, 9473, 9943, 9657, 9208, 6416, 4005, 3686, 5386, 9143, 3954, 8895, 6166, 6624, 5983, 4255, 2659, 7742, 295, 3073, 7483, 222, 5802, 1148, 6734, 9649, 899, 6623, 2955, 9866, 4884, 4681, 5100, 1112, 1279, 1694, 9345, 4746, 8122, 5251, 1098, 6303, 8518, 5514, 7873, 845, 866, 6577, 1278, 5745, 9543, 8781, 1397, 318, 4316, 174, 6798, 731, 2191, 8970, 10008, 2957, 6981, 3604, 5347, 464, 7587, 4691, 1396, 10112, 3847, 7768, 9091, 486, 330, 6899, 7528, 6957, 6723, 600, 4563, 2997, 77, 7570, 4831, 7862, 7805, 9604, 630, 1705, 8471, 6559, 3309, 1345, 4526, 6984, 8307, 6373, 5666, 4779, 4766, 2224, 1126, 7714, 4466, 1562, 1286, 9169, 5609, 8221, 6365, 8585, 8058, 501, 602, 6412, 1662, 8868, 5123, 4423, 225, 6858, 5037, 8555, 9693, 2213, 8580, 6581, 3952, 7383, 2958, 4373, 4834, 3351, 8215, 9322, 9707, 2617, 6530, 7198, 4688, 1252, 4857, 8823, 1142, 4852, 523, 7382, 1781, 3601, 6255, 6546, 1696, 10172, 317, 4472, 3305, 517, 649, 8766, 5833, 3613, 6657, 6066, 7154, 7153, 7901, 526, 8130, 9372, 7540, 986, 9262, 1654, 9892, 2317, 3986, 3690, 8084, 253, 8682, 9053, 4844, 1622, 7706, 2755, 4937, 8415, 3403, 3880, 9294, 263, 5344, 3688, 3070, 6821, 6788, 3815, 8037, 2650, 7378, 27, 2035, 3797, 1145, 8942, 8688, 2504, 5732, 5562, 1671, 9511, 1330, 1869, 9283, 1164, 2129, 9079, 1651, 7333, 1418, 4070, 6963, 4084, 6196, 8623, 10085, 8115, 8129, 4315, 7163, 657, 885, 5167, 6239, 4845, 2111, 7457, 3353, 6824, 7369, 238, 8468, 8508, 2236, 161, 5375, 8560, 7557, 9546, 1710, 829, 9519, 3597, 9934, 8569, 5600, 5645, 4666, 2077, 894, 5051, 8495, 5257, 4156, 1415, 861, 711, 4287, 7124, 3893, 1851, 5822, 10058, 7645, 5948, 10189, 864, 7144, 281, 1618, 4313, 3456, 3407, 9652, 9759, 8443, 4675, 9840, 9832, 9449, 1981, 4492, 2052, 3216, 8677, 8899, 3399, 3812, 1089, 212, 3719, 1825, 995, 315, 6050, 2261, 558, 4788, 4386, 7673, 4226, 2921, 356, 9547, 8819, 3323, 8752, 9590, 3342, 6354, 10180, 1730, 7455, 1758, 5981, 4016, 6573, 7844, 3275, 1071, 8277, 2145, 8684, 3037, 4414, 4705, 2259, 8438, 9272, 9515, 1491, 7902, 928, 3728, 6049, 6611, 1067, 2994, 627, 2131, 5178, 7332, 6635, 5050, 5207, 5364, 817, 6944, 7416, 196, 577, 1328, 1579, 10099, 4830, 1175, 7276, 1729, 7769, 1455, 9723, 1461, 5298, 7594, 7664, 1237, 4181, 9802, 3107, 2262, 6042, 5088, 2641, 1370, 2574, 7061, 8511, 2127, 5072, 9783, 2033, 9314, 3752, 5742, 8790, 9045, 8617, 3469, 9703, 9842, 853, 274, 9931, 2165, 8140, 2478, 7999, 3020, 2148, 5597, 8224, 224, 9016, 4873, 6044, 7481, 105, 934, 5042, 7143, 2114, 1791, 1438, 9567, 6722, 2929, 7175, 5654, 1796, 2209, 5937, 4141, 2643, 4684, 4971, 1149, 8450, 1703, 2708, 5437, 3918, 6632, 8772, 1342, 8589, 6550, 6095, 3528, 7951, 5403, 2219, 872, 4749, 9825, 4798, 4792, 8916, 7758, 6915, 1033, 7271, 7028, 9001, 1932, 3622, 2584, 6045, 587, 3838, 4948, 8009, 8036, 2398, 1980, 2761, 3108, 3581, 8892, 1692, 8497, 2585, 1685, 4727, 8759, 1813, 4819, 1138, 4293, 1034, 9750, 908, 2938, 4711, 4271, 6336, 2700, 2832, 5993, 8344, 3337, 7885, 3799, 7510, 4804, 8816, 3811, 5812, 159, 210, 2001, 3150, 3336, 378, 5687, 1804, 7524, 3015, 7516, 8411, 7057, 9166, 5901, 3790, 343, 2534, 3866, 9490, 6248, 3512, 8820, 1356, 515, 7693, 7929, 2973, 6593, 9618, 5064, 1177, 2917, 5162, 3151, 2556, 7618, 7056, 7157, 10049, 8370, 4734, 2716, 4997, 5638, 3970, 726, 7580, 133, 9461, 3333, 3976, 3089, 3720, 5233, 327, 6743, 5193, 7078, 1366, 4920, 2115, 2094, 977, 796, 5447, 8727, 6080, 7909, 95, 275, 5838, 6352, 6604, 1557, 2247, 5333, 6881, 2319, 9970, 2575, 6882, 2564, 5895, 6772, 8522, 7170, 197, 7552, 2447, 8733, 298, 8649, 3477, 930, 5183, 5352, 1857, 8863, 1953, 6070, 4670, 5068, 9220, 2032, 4960, 1875, 4867, 3207, 7603, 8811, 6089, 2882, 1535, 9502, 1263, 1044, 7946, 540, 5130, 2257, 4780, 3326, 2961, 3018, 5063, 3242, 6945, 1193, 9857, 6370, 445, 2123, 2513, 8946, 8070, 3577, 2695, 4281, 7588, 3330, 2871, 3607, 9836, 1369, 8855, 6589, 5476, 5602, 5653, 3556, 251, 5719, 7380, 7227, 7073, 8829, 7296, 6316, 1307, 3243, 3173, 5277, 1561, 6664, 496, 9882, 1029, 2263, 6560, 10144, 2066, 2008, 5340, 9082, 5486, 7443, 3521, 2062, 846, 2607, 10119, 2808, 9357, 9761, 1964, 9742, 7142, 7316, 2439, 677, 4450, 9874, 7843, 9298, 5139, 6786, 6410, 5945, 8769, 9467, 5692, 4026, 8441, 6, 3214, 3983, 1773, 4208, 299, 4521, 522, 323, 8998, 2486, 2480, 3467, 989, 3355, 3641, 5590, 9948, 8098, 5949, 6078, 1035, 8591, 369, 10100, 2146, 7229, 8832, 7652, 5122, 5888, 9935, 7612, 5363, 1327, 6956, 4108, 8926, 1049, 9807, 4321, 9453, 2742, 6909, 6663, 6277, 6778, 2662, 9650, 4806, 5606, 5759, 3660, 2484, 9523, 2747, 7454, 2724, 2500, 6342, 3269, 4205, 9789, 2702, 9265, 2467, 3825, 2606, 1947, 1797, 7747, 4872, 137, 1933, 5819, 5776, 5256, 3313, 3053, 880, 8875, 4369, 9482, 1584, 3160, 7629, 1842, 9063, 10029, 8514, 1529, 3328, 49, 969, 8138, 9813, 8480, 5665, 6548, 7219, 3755, 2502, 2072, 474, 1731, 1333, 417, 8539, 3257, 3520, 8659, 752, 8707, 3308, 9087, 7813, 5845, 3781, 8397, 7238, 3475, 6434, 9754, 4121, 623, 8227, 4497, 6922, 2734, 946, 8834, 5934, 4403, 8067, 3746, 503, 5689, 4890, 2308, 8255, 7093, 5873, 3499, 3656, 553, 4697, 4513, 58, 10026, 7185, 9476, 2304, 232, 1670, 3707, 6871, 4658, 4431, 2852, 8107, 6123, 6090, 8174, 5478, 6461, 6591, 6789, 4700, 9004, 697, 6199, 836, 7860, 6677, 1094, 6043, 354, 8777, 7206, 2988, 1922, 5851, 7130, 9197, 1131, 5540, 8573, 5707, 692, 3582, 231, 1006, 8293, 6445, 6476, 2361, 8693, 5733, 2122, 439, 3271, 2228, 6496, 6517, 8913, 4495, 616, 6932, 5601, 1390, 3596, 4936, 3730, 3232, 5640, 5531, 9958, 5736, 4530, 9909, 4396, 3388, 6688, 1741, 7985, 1982, 2006, 4637, 9479, 2693, 3995, 7356, 3701, 6047, 2712, 4173, 4295, 9086, 1, 5302, 2477, 9787, 9452, 9026, 3886, 7499, 5043, 423, 5204, 5116, 468, 5317, 5165, 2683, 646, 8481, 7715, 4696, 6532, 1759, 5497, 4116, 1519, 4368, 1361, 5491, 2552, 25, 2636, 1712, 7809, 807, 5118, 7371, 1935, 4520, 6141, 9258, 5900, 1828, 2944, 2364, 3256, 4123, 3387, 6605, 7236, 4262, 2810, 5295, 8031, 9563, 4701, 7912, 1423, 8523, 8512, 3943, 7829, 9847, 5392, 4832, 1250, 6712, 668, 3626, 7956, 6274, 2927, 8162, 7176, 1880, 9454, 1435, 6096, 1194, 3736, 9614, 5885, 4653, 6773, 8882, 4905, 7686, 1381, 2401, 3038, 10168, 3340, 5461, 1462, 7147, 3147, 3974, 5377, 6005, 7213, 5059, 8042, 9582, 7665, 1231, 6820, 5402, 4441, 201, 3385, 6684, 4394, 4332, 8862, 3875, 8420, 8525, 6747, 6901, 966, 1580, 5966, 2483, 9129, 8598, 2949, 7622, 957, 2177, 5963, 7623, 2158, 1494, 9591, 3980, 7766, 66, 363, 6644, 2397, 9020, 4961, 8741, 7377, 9605, 6579, 228, 6466, 2141, 3479, 3962, 9817, 8379, 5235, 8624, 4816, 554, 6721, 6144, 3116, 5799, 6674, 6085, 8430, 2449, 9955, 4410, 5777, 5771, 2874, 3174, 8940, 3193, 1100, 8117, 1938, 7904, 6498, 7848, 7054, 2519, 4709, 8857, 5385, 8700, 6383, 7941, 7479, 8804, 2338, 1590, 8192, 9992, 7691, 971, 5986, 5323, 2678, 3576, 7207, 9404, 2784, 7668, 3047, 142, 9332, 6830, 9548, 8848, 2707, 2887, 8538, 10010, 1213, 1059, 595, 5081, 7317, 6369, 9212, 365, 2796, 5605, 9290, 2410, 3476, 10192, 7135, 8217, 9368, 3827, 3621, 1179, 5405, 6626, 10064, 1690, 3642, 3004, 8019, 1046, 2651, 3777, 7119, 6439, 3871, 4292, 2853, 1866, 380, 9797, 342, 2612, 3606, 3907, 1872, 10075, 3895, 338, 7366, 2814, 8650, 7973, 9928, 3118, 8093, 1810, 5964, 1870, 7523, 2962, 8156, 2157, 8071, 9907, 7696, 4996, 2102, 7005, 208, 5058, 7132, 7344, 3751, 4113, 792, 10101, 7546, 10048, 8268, 2935, 3764, 5979, 3858, 7869, 1582, 9374, 6815, 8358, 9160, 2136, 6161, 9952, 1892, 7605, 6679, 1543, 6971, 9498, 4687, 3559, 5284, 6246, 5675, 1901, 5332, 4911, 2628, 4107, 9630, 367, 1336, 9915, 5453, 136, 5188, 3973, 7197, 4596, 5144, 4385, 9028, 7764, 4348, 5984, 1075, 8455, 8981, 6522, 3844, 4772, 8253, 1587, 9304, 6411, 1669, 5248, 4504, 8788, 246, 3861, 1655, 7461, 8309, 9399, 1746, 3553, 4784, 9383, 3032, 2826, 8487, 9114, 6728, 4722, 9938, 1130, 6672, 6341, 6527, 5786, 1399, 8807, 4557, 3713, 2953, 9412, 2668, 3153, 6142, 5548, 781, 1745, 1691, 1027, 17, 1490, 8034, 4657, 5168, 4083, 41, 1288, 2256, 6710, 6107, 6069, 9358, 5279, 7962, 8965, 7305, 7204, 1576, 6683, 1621, 220, 4007, 4134, 5688, 6746, 4635, 8755, 2510, 5024, 8422, 3644, 5157, 8867, 10181, 1480, 5466, 5052, 4928, 7164, 271, 2279, 2057, 1285, 2635, 6077, 5422, 6064, 9425, 4279, 7628, 903, 4841, 4130, 5914, 1497, 3639, 4243, 6891, 2911, 1521, 10132, 6779, 2711, 2801, 6493, 6603, 4560, 9804, 510, 455, 2085, 6680, 1997, 7436, 2870, 4509, 9019, 839, 9039, 7757, 4460, 1377, 560, 6015, 8780, 5225, 3009, 350, 4787, 9336, 2133, 9146, 4406, 1308, 155, 545, 8672, 219, 3376, 5871, 10081, 2566, 4789, 533, 4603, 9786, 5027, 1601, 541, 1974, 7801, 6895, 6054, 157, 9202, 1533, 9369, 8711, 2922, 5511, 139, 6469, 9025, 8852, 4782, 8957, 5912, 6353, 1030, 1220, 6333, 6201, 1291, 1918, 2176, 5621, 3899, 4039, 7750, 8860, 5082, 4214, 3451, 948, 3533, 2629, 1050, 9431, 9592, 88, 5946, 8845, 5515, 169, 8562, 1637, 4535, 4277, 7424, 5906, 3826, 2652, 2302, 6007, 5158, 1627, 5201, 4984, 5716, 6455, 1838, 1481, 8646, 7498, 182, 3156, 1558, 730, 9496, 2974, 292, 1492, 4073, 10145, 1404, 9835, 2562, 7347, 9767, 6543, 6816, 7151, 9953, 7375, 2863, 8602, 7734, 3100, 3443, 9394, 7019, 4581, 8083, 1477, 7162, 628, 2850, 1608, 3286, 3164, 3867, 2827, 7772, 9391, 4878, 4106, 4428, 9942, 9386, 598, 6549, 4650, 5326, 4865, 629, 7899, 2323, 3664, 1934, 840, 6902, 6102, 2290, 5956, 7463, 7403, 2904, 1305, 9352, 694, 5272, 8661, 3964, 9830, 7489, 4838, 4488, 1184, 7020, 5797, 9455, 5944, 2528, 1824, 1613, 8052, 5018, 179, 5890, 5679, 5720, 2300, 7828, 5564, 6204, 9983, 2193, 9513, 5464, 5913, 6308, 9615, 3524, 4556, 9070, 6766, 3251, 3924, 1135, 8231, 9812, 7270, 7810, 4304, 2722, 9699, 1248, 5368, 707, 7948, 3996, 5810, 8077, 6158, 9108, 3209, 10121, 2838, 800, 5761, 8920, 3314, 527, 61, 171, 1294, 5608, 1425, 4760, 2913, 9609, 4346, 3941, 7911, 9790, 5142, 8504, 7895, 9164, 6835, 5306, 4337, 1087, 3516, 8437, 321, 1487, 2542, 5513, 4758, 1719, 3605, 3210, 2012, 6586, 5080, 9245, 8884, 2840, 7879, 1032, 3079, 6954, 7077, 3653, 3857, 9597, 5921, 8599, 985, 6458, 10066, 5800, 205, 3092, 9066, 3292, 8564, 4235, 8445, 1914, 115, 8701, 5125, 10146, 7196, 6051, 1893, 6921, 2348, 478, 9748, 3848, 9365, 1748, 8257, 6312, 6139, 3608, 2933, 3067, 2931, 6625, 751, 4791, 3773, 6401, 3634, 5668, 5673, 285, 7617, 6011, 572, 9507, 5339, 4051, 7564, 4941, 9210, 4974, 4478, 5854, 7350, 7091, 6286, 2139, 8932, 7323, 4790, 5951, 4066, 4391, 8099, 5, 1243, 5176, 9271, 2284, 5970, 2875, 1827, 6653, 8503, 3572, 675, 7228, 5035, 4842, 795, 8209, 3285, 6718, 4230, 4429, 1631, 5577, 4828, 10082, 9451, 4490, 5941, 681, 6838, 9525, 7096, 248, 3488, 974, 4311, 6876, 5637, 7849, 36, 5398, 6359, 9908, 9808, 9927, 1887, 2630, 848, 4615, 1205, 4607, 1028, 1802, 8686, 1202, 5644, 1723, 1178, 9528, 9806, 2771, 1485, 1656, 539, 937, 3169, 6241, 4347, 3837, 8847, 4224, 6200, 1597, 296, 2900, 2244, 8074, 1379, 7041, 6192, 2325, 272, 252, 5258, 5534, 8410, 10055, 6422, 7830, 831, 7500, 2143, 8830, 9397, 6067, 1767, 4921, 9021, 270, 3406, 6233, 8466, 4416, 2160, 5198, 8607, 7245, 6980, 4947, 9059, 6618, 8941, 10088, 59, 6965, 841, 9929, 4669, 7240, 9401, 7882, 1657, 7749, 2522, 3514, 6351, 2376, 2369, 1699, 7840, 9852, 69, 1265, 666, 8313, 3747, 6913, 3618, 938, 7502, 7970, 6658, 4168, 8007, 7324, 6216, 2135, 952, 5407, 1457, 3062, 6524, 7925, 9727, 8269, 500, 5238, 5070, 8548, 2774, 6843, 8386, 1966, 8551, 6326, 1818, 2537, 3265, 4802, 9088, 5556, 265, 4620, 5288, 7942, 5456, 1646, 6651, 8172, 7243, 882, 1985, 7880, 1930, 2419, 8359, 8638, 3225, 8263, 7320, 4714, 7938, 1509, 1833, 2837, 5618, 3661, 2275, 820, 5695, 5310, 4880, 10110, 8072, 9280, 5917, 7277, 10155, 7842, 3245, 7095, 5015, 4057, 4377, 10046, 9620, 3237, 5752, 5336, 2906, 4730, 1898, 8133, 2070, 6402, 8148, 382, 2099, 8866, 2342, 6378, 8979, 9828, 9691, 178, 4341, 548, 3711, 4046, 4825, 2211, 7370, 1460, 4407, 3589, 7811, 886, 3830, 4392, 7304, 6284, 3735, 8724, 6256, 5047, 6562, 8576, 6169, 4756, 7517, 4447, 8175, 9877, 9681, 1970, 10108, 6094, 9576, 1437, 4356, 6306, 6767, 9343, 547, 1309, 6155, 3324, 2660, 766, 2848, 3789, 2468, 7381, 1549, 4877, 5525, 3259, 1314, 5210, 724, 2670, 3494, 3172, 8366, 8883, 392, 1172, 4600, 2891, 2159, 7957, 2175, 645, 2017, 5750, 62, 1724, 983, 6111, 9510, 34, 9422, 2167, 2567, 80, 1790, 1392, 3573, 5163, 4399, 20, 7059, 3021, 9860, 6702, 9678, 4548, 9373, 4438, 810, 9731, 1402, 8907, 4868, 5862, 4104, 520, 4786, 4209, 2226, 10149, 8372, 2463, 9081, 1859, 6315, 7318, 10073, 6731, 236, 6854, 6955, 596, 6775, 8833, 9014, 8976, 2238, 9140, 8846, 8114, 1890, 78, 2392, 3195, 1416, 8657, 9930, 9945, 4454, 9805, 6282, 7736, 2786, 653, 8043, 2205, 8961, 1769, 3289, 1946, 9584, 9534, 6991, 10131, 2437, 8211, 6634, 8377, 8876, 7763, 2336, 2735, 9811, 7822, 2956, 7559, 6121, 8561, 3748, 1372, 661, 8317, 9625, 4778, 5827, 3380, 7074, 6564, 1229, 1665, 6035, 3926, 2044, 8572, 7991, 6939, 9460, 8634, 2591, 3334, 7702, 3111, 9579, 8467, 3531, 7044, 5571, 9359, 4633, 5060, 516, 9772, 2105, 8362, 2245, 5412, 512, 8246, 4027, 1983, 4133, 9138, 5115, 2200, 9906, 3522, 1689, 10009, 4818, 10123, 8801, 1284, 1262, 919, 5175, 4609, 1630, 7959, 6872, 4080, 8542, 2254, 1912, 9755, 9848, 8381, 3566, 9792, 5772, 450, 1374, 4531, 3674, 9603, 6185, 8333, 4785, 4740, 6836, 2732, 6103, 4096, 6451, 5657, 10128, 949, 990, 849, 7303, 6979, 4757, 5031, 9198, 1931, 7888, 8182, 7974, 4720, 6889, 1296, 4162, 4699, 7007, 4849, 4856, 4444, 8568, 1104, 9222, 4189, 3137, 9849, 9190, 6973, 7470, 9643, 1776, 3412, 9585, 1000, 15, 8063, 2441, 3236, 8948, 8506, 2163, 4565, 689, 3648, 3849, 7214, 2592, 7511, 6826, 5769, 8631, 6165, 4886, 9973, 3904, 8427, 6371, 9904, 1874, 8622, 2765, 5278, 2390, 7066, 9301, 5171, 4533, 5240, 5559, 2100, 875, 3261, 975, 3768, 9446, 2282, 5474, 3868, 9241, 4664, 1368, 10034, 1939, 2002, 4655, 4372, 6449, 5595, 2383, 8887, 7778, 3471, 6978, 8919, 5926, 4858, 9712, 3474, 8533, 7049, 978, 6472, 9574, 6300, 6474, 7685, 9902, 9408, 10188, 3725, 8049, 2674, 5641, 3663, 5222, 5864, 1714, 8472, 5141, 3788, 2496, 9244, 4276, 267, 4661, 1321, 5267, 361, 1125, 8124, 4614, 6375, 5086, 1169, 723, 109, 4137, 4424, 9964, 3382, 9880, 6232, 6828, 7307, 3166, 9610, 7148, 2110, 3934, 9889, 5134, 412, 6794, 7081, 1883, 8284, 4754, 7950, 3301, 4071, 39, 1233, 3033, 3386, 9501, 2623, 868, 5744, 7102, 10052, 432, 283, 5633, 4126, 3510, 5536, 3008, 1322, 6598, 4712, 3738, 6935, 5738, 4914, 5647, 6518, 6191, 1552, 2880, 754, 2366, 6157, 1036, 1066, 3284, 5991, 3614, 1015, 8810, 440, 7937, 7027, 1433, 3645, 2766, 2621, 9666, 2885, 3991, 9855, 1280, 8888, 332, 8708, 151, 5622, 7529, 5834, 6784, 8060, 2314, 8691, 9893, 3371, 4891, 8266, 1545, 7774, 4401, 6347, 7745, 9176, 6114, 3503, 1616, 7542, 2897, 5381, 4456, 4489, 8717, 2424, 2061, 4626, 7181, 4525, 8746, 4459, 7727, 9469, 951, 8800, 9729, 2431, 7069, 5661, 5942, 891, 8985, 945, 7244, 8812, 9480, 8207, 4621, 1482, 429, 9549, 648, 9542, 8446, 9184, 8233, 5613, 6433, 2527, 4796, 6812, 3888, 9165, 3394, 1319, 8230, 2417, 5373, 6574, 5643, 1896, 2743, 6240, 2440, 6860, 1681, 2333, 8047, 4485, 4117, 1207, 5881, 6323, 9296, 4334, 778, 8365, 9375, 1996, 6934, 3816, 9434, 2051, 984, 3555, 4775, 2847, 2560, 7123, 1911, 2718, 9936, 2825, 4272, 3530, 6250, 5555, 4176, 4197, 9105, 6100, 1310, 1565, 2618, 1009, 4219, 9219, 7995, 7530, 5108, 5480, 8331, 7626, 6377, 9537, 7352, 6465, 8475, 3574, 2132, 9986, 3897, 8827, 6960, 3364, 7752, 1038, 5976, 6061, 8675, 967, 5783, 2389, 4836, 2291, 1117, 6076, 5950, 2083, 5634, 6678, 9714, 832, 6454, 6272, 3123, 7927, 8826, 4246, 2881, 3898, 3347, 7855, 8440, 6244, 8208, 372, 10104, 962, 1471, 5566, 2258, 4161, 497, 5630, 7590, 6000, 336, 9247, 9685, 7488, 10013, 3152, 7336, 8929, 4286, 7002, 217, 9628, 1614, 3045, 2080, 7405, 1604, 622, 5379, 6441, 4087, 10047, 9448, 7193, 2637, 687, 1941, 5296, 7759, 6280, 4296, 6852, 8203, 1666, 4462, 4178, 6514, 680, 6780, 3439, 10057, 7896, 9913, 737, 3717, 5075, 3204, 7495, 1380, 5213, 1750, 3114, 2788, 4158, 3537, 5930, 5808, 6953, 5589, 329, 8765, 9651, 9632, 1593, 254, 3181, 11, 4498, 3453, 8579, 3685, 5322, 8604, 2227, 10086, 2908, 6516, 1757, 431, 3162, 6297, 9180, 10107, 4382, 4616, 5460, 9788, 4092, 6801, 8267, 5475, 5209, 9478, 1755, 2572, 9674, 2640, 4539, 4577, 10077, 9354, 3579, 1553, 5469, 6275, 5509, 2731, 6479, 3348, 3920, 8719, 1394, 8963, 1586, 1300, 1215, 9285, 5501, 8330, 9427, 7513, 5334, 5959, 3291, 7459, 4265, 2688, 4543, 7743, 9257, 6880, 7427, 6197, 1606, 7462, 9131, 6670, 7641, 815, 9753, 3230, 9586, 1945, 1054, 7621, 4939, 9321, 7039, 2769, 2971, 4821, 8732, 4764, 7050, 9196, 9568, 5806, 6268, 8051, 3708, 4544, 8674, 3119, 8982, 2312, 4269, 6917, 4053, 4090, 802, 8059, 8825, 1717, 9801, 4969, 3779, 8750, 7497, 9011, 5508, 10113, 5874, 8220, 2155, 976, 824, 2104, 7146, 8540, 5861, 2347, 2095, 7569, 2942, 9777, 2868, 9276, 1140, 617, 6690, 8056, 3239, 1197, 3484, 8987, 4167, 4207, 5264, 2071, 9524, 6966, 3159, 8171, 5870, 2632, 5006, 2192, 9080, 3817, 5269, 6292, 4759, 3472, 5867, 6484, 6311, 2214, 1434, 2573, 286, 8841, 8346, 3404, 5185, 8996, 2119, 1414, 7409, 779, 7343, 7741, 5919, 999, 9551, 2242, 2764, 67, 9203, 7202, 8893, 7945, 2481, 7648, 9239, 1133, 9721, 6892, 376, 9316, 5287, 7933, 1585, 8953, 4268, 3712, 10164, 4767, 2273, 9580, 9398, 47, 5197, 917, 4470, 3709, 3675, 3028, 4151, 2835, 6462, 3310, 7817, 5468, 8500, 7983, 8877, 10147, 1904, 6689, 7522, 712, 4713, 183, 10140, 1771, 5290, 878, 2116, 7017, 3489, 3076, 9330, 3427, 6329, 8621, 3307, 5969, 7367, 9619, 5962, 6186, 1559, 7807, 2187, 6404, 6705, 4362, 8983, 9558, 166, 9252, 7329, 2979, 5529, 932, 5857, 1008, 519, 6413, 4483, 8290, 2709, 6345, 8489, 211, 2589, 4975, 4283, 988, 7791, 3003, 4726, 5255, 5677, 444, 10184, 941, 7088, 6582, 8183, 1230, 3807, 416, 215, 5211, 8528, 5089, 1410, 2909, 5518, 8041, 1626, 419, 1464, 6851, 1469, 2889, 8524, 5933, 6467, 8683, 9800, 8640, 4409, 6238, 6938, 9382, 1225, 1836, 9229, 2550, 10083, 4665, 8191, 7293, 3706, 64, 9716, 3603, 1203, 7024, 8990, 1371, 4464, 4724, 9127, 9171, 855, 9856, 5424, 8529, 5394, 2877, 2250, 6379, 6406, 5866, 6528, 4411, 2936, 7712, 1501, 63, 9846, 9921, 4985, 5686, 1664, 9676, 6856, 6140, 7348, 915, 4910, 9785, 638, 4552, 4056, 158, 770, 9512, 6685, 3293, 2360, 898, 1329, 73, 8595, 9940, 8984, 4612, 5218, 1001, 7447, 9209, 7903, 4359, 3676, 9850, 867, 3785, 2795, 4442, 5639, 960, 184, 3793, 9738, 213, 7284, 9926, 2549, 7667, 3993, 5425, 7722, 6714, 7001, 2041, 2321, 4951, 9982, 1468, 5328, 5607, 6177, 964, 5078, 2485, 5056, 9475, 3982, 4549, 3202, 3557, 2647, 6187, 8435, 4425, 2657, 9153, 5038, 498, 6004, 290, 6138, 8909, 8323, 4154, 4822, 4021, 8109, 5103, 6545, 7960, 163, 760, 1574, 8336, 604, 7719, 2950, 4923, 1070, 192, 3106, 8702, 4263, 4082, 6585, 3990, 8490, 3014, 953, 3413, 9617, 8288, 2223, 481, 7286, 3212, 5775, 6332, 756, 2544, 4973, 6578, 8955, 2976, 6695, 8597, 4068, 3258, 5642, 1249, 5205, 3623, 1581, 7349, 1668, 4735, 9884, 5066, 4889, 6886, 420, 8179, 7491, 3317, 7037, 6646, 7858, 6749, 7607, 6890, 4741, 4692, 1306, 1463, 7358, 8633, 116, 6109, 5672, 1395, 4776, 8502, 8147, 7400, 7900, 8176, 8584, 170, 4847, 1430, 605, 9274, 4850, 7649, 1176, 7655, 5428, 3316, 3650, 5170, 6659, 2384, 4918, 10011, 3710, 5313, 3517, 2181, 4988, 3201, 9034, 2185, 4050, 1019, 2125, 674, 9858, 5880, 3113, 7327, 4375, 8645, 4048, 8413, 9303, 8831, 7335, 2620, 488, 4592, 6230, 6587, 2069, 5671, 3754, 1190, 9539, 4716, 7060, 9697, 8328, 1592, 8558, 1367, 449, 5418, 1163, 2341, 1786, 3086, 6622, 2371, 2098, 8296, 7342, 8861, 6681, 8021, 362, 339, 7506, 6645, 9141, 45, 9044, 4035, 4326, 9305, 9997, 719, 7514, 9032, 5055, 8395, 8283, 4017, 8152, 7823, 4558, 7748, 2142, 2432, 7264, 6075, 4551, 9487, 2350, 5182, 7586, 2654, 2823, 3602, 7824, 1602, 9841, 5065, 3828, 5582, 8849, 992, 3887, 6526, 1848, 3064, 8423, 5765, 3726, 3339, 347, 1675, 8567, 5335, 6505, 8553, 5734, 9251, 4598, 5128, 3460, 3034, 3329, 7487, 1241, 7690, 1298, 1260, 5208, 6912, 9049, 9031, 5578, 6693, 8142, 4554, 2655, 4773, 734, 5177, 700, 3600, 8959, 3561, 4448, 4604, 4, 2896, 3949, 6119, 5400, 8614, 8210, 3397, 8673, 10038, 5526, 6202, 7914, 721, 3278, 889, 1313, 8154, 9470, 1483, 9690, 1853, 7713, 2729, 5724, 6883, 2010, 7646, 1012, 2, 9225, 4150, 1764, 3889, 2664, 7894, 2726, 7417, 8412, 1936, 187, 5260, 2029, 463, 7576, 562, 3223, 8951, 7531, 8184, 3775, 6149, 8809, 4184, 1099, 6110, 1072, 3692, 1993, 1674, 3140, 7030, 9463, 6639, 206, 2714, 9223, 7969, 6590, 5087, 9315, 319, 6823, 1777, 9700, 8097, 1706, 9327, 4194, 2406, 5682, 6706, 6475, 2842, 1124, 3389, 559, 1323, 9061, 4659, 8426, 9600, 5848, 1967, 2648, 3091, 581, 1080, 9024, 1916, 8464, 3769, 7954, 1325, 5737, 1807, 9616, 8144, 9009, 8797, 6132, 3968, 5426, 6916, 2515, 8020, 8401, 1412, 1446, 1350, 120, 1538, 4457, 3029, 7799, 7619, 3951, 5999, 2673, 5704, 7273, 4232, 5779, 2345, 1451, 4860, 7456, 2470, 3915, 662, 9607, 5397, 6850, 2748, 743, 4632, 9064, 2824, 4024, 4280, 911, 6318, 9888, 3809, 5265, 1174, 7878, 6257, 4893, 3145, 7089, 4613, 1976, 10089, 8062, 5230, 7178, 9985, 3515, 3808, 3832, 852, 2704, 877, 2202, 28, 650, 9720, 10033, 7141, 8722, 3312, 5458, 6172, 7012, 6470, 4750, 873, 6948, 9560, 4965, 6037, 7385, 9762, 5146, 9919, 3883, 6024, 3206, 226, 144, 5327, 9535, 7699, 6508, 1522, 2331, 7216, 9269, 9661, 4322, 9253, 4463, 6754, 3546, 6388, 8118, 8900, 9163, 4240, 9349, 24, 7480, 2436, 3167, 6588, 7376, 7781, 8799, 2571, 4044, 4289, 3356, 124, 414, 4568, 4297, 1005, 326, 9553, 9119, 6990, 5025, 3375, 3478, 9029, 3019, 6136, 2487, 6686, 100, 6409, 8305, 6082, 8201, 3344, 4484, 1629, 5349, 3677, 2518, 2785, 2391, 8483, 6962, 9289, 9458, 7046, 4254, 8886, 7567, 5416, 7865, 4584, 4228, 6245, 1700, 5876, 5166, 8334, 7561, 6698, 1752, 1378, 7806, 3031, 1623, 6063, 7224, 2776, 4629, 4938, 9981, 8045, 7556, 7265, 6884, 9181, 7215, 6400, 7086, 3196, 5029, 198, 4249, 2093, 9050, 1403, 1102, 9596, 9167, 8188, 2860, 8582, 10156, 4597, 389, 6497, 3984, 3354, 4809, 10037, 5483, 4258, 3620, 8474, 2337, 4171, 5992, 4094, 4306, 364, 8491, 4883, 4589, 156, 3802, 7180, 733, 5320, 6337, 8280, 8608, 5749, 6262, 5817, 2535, 9694, 5793, 2578, 4247, 5542, 6159, 6029, 4742, 7192, 2671, 7579, 8993, 544, 2543, 2476, 8216, 8458, 6511, 6305, 1002, 2000, 9051, 5441, 8890, 8720, 9005, 6610, 5228, 6940, 8066, 2777, 8035, 1785, 1011, 2324, 9030, 6495, 4662, 3343, 8670, 6006, 5781, 1721, 7029, 4946, 7212, 3588, 4421, 9494, 8914, 7915, 4962, 4899, 9438, 1432, 6271, 7104, 4038, 6768, 7111, 1136, 1958, 2822, 961, 7601, 2340, 8357, 1354, 2806, 2293, 4093, 10030, 9424, 1159, 7082, 3090, 10096, 8454, 4188, 5341, 4170, 9261, 3220, 3252, 3304, 6643, 2820, 6612, 9254, 6023, 7259, 10178, 7660, 4018, 4239, 3824, 8046, 3300, 499, 5459, 6040, 10103, 5436, 8167, 7210, 8905, 3132, 2993, 1965, 7553, 6846, 3421, 7884, 9595, 6619, 7940, 3287, 4595, 9286, 759, 4954, 8281, 8033, 9895, 9182, 542, 4640, 9256, 2060, 7717, 8005, 6782, 9633, 6535, 6666, 334, 6803, 1709, 10152, 1849, 9518, 2349, 8459, 10004, 3714, 6989, 1512, 9724, 1031, 534, 2638, 8016, 7814, 6079, 6608, 5393, 6650, 8660, 1449, 5804, 3069, 1779, 6926, 6033, 2281, 6302, 4453, 8320, 7508, 9544, 7571, 3632, 4989, 504, 2627, 6787, 8592, 7053, 6977, 4330, 2738, 606, 4363, 1128, 89, 1281, 4072, 4229, 428, 6217, 7062, 2772, 7589, 4486, 5528, 5357, 6783, 493, 1013, 6179, 833, 8663, 2452, 1095, 9174, 5275, 6041, 5551, 9914, 1188, 5493, 8723, 6395, 1424, 3988, 7275, 4238, 8029, 7353, 4583, 4896, 4574, 5376, 3925, 316, 9205, 8380, 436, 9266, 9803, 5297, 6264, 7732, 107, 2791, 10012, 780, 9538, 8994, 2355, 8186, 6833, 9267, 4434, 2968, 7309, 1811, 1436, 2201, 5792, 8496, 6540, 331, 8761, 3724, 1633, 1040, 262, 1384, 6117, 7189, 5308, 9683, 2912, 5455, 6266, 2310, 6154, 10000, 1547, 6733, 4103, 1546, 607, 1320, 5498, 8687, 9923, 6435, 5631, 6108, 345, 825, 9489, 479, 5698, 2901, 4353, 4944, 814, 8910, 5312, 1198, 7800, 1873, 599, 8806, 8218, 4191, 8532, 5173, 2787, 8710, 10120, 8578, 8666, 9894, 9947, 7536, 5767, 621, 4967, 7602, 1475, 10093, 3670, 8382, 4622, 851, 3565, 3002, 5918, 3938, 108, 9411, 7672, 1676, 7418, 4656, 3435, 7241, 51, 6148, 7359, 6717, 7939, 2663, 1236, 6174, 7058, 4204, 5807, 1218, 5206, 6946, 9570, 379, 5129, 4862, 7184, 9124, 4685, 5741, 6322, 4422, 7765, 1620, 394, 7106, 1505, 3541, 9675, 1792, 3483, 6568, 9111, 7415, 1844, 5079, 9796, 8003, 83, 242, 9660, 7591, 10114, 181, 502, 3440, 7, 7021, 3227, 5351, 8637, 9887, 5470, 193, 1408, 1157, 7525, 9845, 5388, 5223, 7478, 884, 2199, 3143, 1165, 843, 1312, 3395, 579, 3611, 6227, 8364, 4019, 6009, 5567, 10148, 765, 6771, 7446, 400, 1268, 5980, 3761, 1564, 8651, 3149, 8565, 9581, 8574, 7606, 4682, 6048, 9873, 5676, 8654, 9161, 2851, 1258, 1928, 4148, 5444, 4963, 5009, 1839, 6224, 7839, 979, 9058, 8874, 2296, 8757, 9636, 3486, 2967, 2375, 6084, 4935, 6584, 5656, 9833, 994, 10015, 2207, 1196, 926, 6976, 9794, 940, 6900, 3787, 3419, 2053, 5662, 5858, 6444, 9667, 5259, 5350, 1247, 8012, 9999, 3087, 7853, 5112, 2215, 4040, 1658, 4250, 1895, 8878, 9002, 3917, 6687, 5172, 1429, 1624, 4032, 7492, 6521, 2692, 470, 9464, 6150, 5907, 3498, 2563, 4515, 8017, 7574, 511, 6122, 6206, 7916, 2694, 3327, 8731, 9776, 9000, 3979, 883, 1537, 2686, 113, 8311, 2444, 6806, 6016, 5348, 132, 7820, 5132, 7773, 3368, 5850, 7474, 9287, 9235, 3978, 43, 5678, 6859, 3819, 10115, 5826, 6855, 6602, 3215, 665, 4076, 5928, 8992, 6214, 3013, 6911, 2018, 1864, 2004, 2494, 7754, 3103, 5395, 9704, 4420, 4519, 1648, 7134, 1735, 2456, 639, 4968, 8095, 4213, 847, 1765, 2954, 3806, 8600, 7638, 8442, 10072, 7075, 10195, 1108, 7043, 9360, 2815, 10130, 1910, 6750, 5546, 9961, 7072, 2590, 3165, 3170, 8753, 7771, 5816, 3850, 7680, 110, 2212, 2367, 9433, 1595, 1274, 2505, 2841, 6671, 234, 2482, 8758, 8237, 4527, 3273, 5798, 3892, 2551, 7013, 3496, 7306, 2019, 3981, 9168, 8587, 8204, 10018, 7740, 9035, 4898, 101, 4892, 2446, 6258, 4220, 5360, 7921, 5636, 7126, 7614, 9435, 8110, 6428, 10053, 8964, 5785, 1949, 4351, 8515, 1542, 9040, 4605, 337, 4180, 591, 4045, 7932, 2846, 4419, 7611, 5406, 4393, 8332, 9624, 172, 2495, 8703, 7716, 2725, 564, 9299, 9293, 568, 6098, 7290, 467, 611, 5694, 6314, 4149, 3473, 7850, 5159, 4294, 7859, 641, 5717, 4015, 910, 9656, 8995, 5574, 1277, 713, 6456, 0, 1568, 8173, 7761, 8975, 2811, 1500, 4736, 2770, 2894, 4285, 288, 1884, 530, 7978, 9627, 8705, 7398, 2919, 2845, 128, 8032, 3628, 1886, 4445, 5591, 1299, 10124, 3741, 2951, 9217, 7465, 1915, 9277, 8123, 842, 2991, 2854, 8295, 2866, 5629, 2353, 9056, 1541, 8235, 8436, 9006, 9658, 6362, 240, 981, 1226, 1858, 826, 3059, 2015, 7998, 4959, 3822, 1162, 2388, 1382, 7565, 6065, 485, 9822, 68, 3048, 9384, 4388, 4508, 5684, 9377, 5434, 844, 300, 1419, 5358, 2892, 9069, 7121, 2963, 8840, 8962, 9421, 5451, 1517, 6751, 575, 6885, 7363, 9188, 3105, 9899, 60, 8433, 9420, 2231, 6905, 9837, 6958, 1346, 90, 5770, 7700, 5143, 4829, 6176, 9495, 4274, 5147, 7253, 7174, 6969, 4978, 3759, 6168, 4689, 9170, 5307, 7501, 8476, 6147, 524, 9869, 2425, 2878, 3063, 5774, 5756, 1391, 8198, 9638, 4690, 4077, 1118, 7898, 10167, 6420, 3240, 6656, 4532, 8851, 4371, 9317, 3534, 10154, 3640, 6606, 3228, 2633, 2217, 9109, 119, 3157, 2173, 698, 349, 2520, 6847, 935, 8139, 1955, 3423, 9237, 2680, 3366, 8163, 4725, 3742, 1625, 5473, 7631, 9350, 7458, 6813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10196/10196 [==============================] - 4730s 464ms/step - loss: 0.4918 - f1: 0.8191 - acc: 0.8297 - val_loss: 0.3382 - val_f1: 0.8720 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.87195, saving model to hrnet_superpixel.hdf5\n",
      "Epoch 2/500\n",
      "10196/10196 [==============================] - 4030s 395ms/step - loss: 0.2495 - f1: 0.9059 - acc: 0.9072 - val_loss: 0.2638 - val_f1: 0.9002 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.87195 to 0.90019, saving model to hrnet_superpixel.hdf5\n",
      "Epoch 3/500\n",
      " 2883/10196 [=======>......................] - ETA: 46:14 - loss: 0.1848 - f1: 0.9290 - acc: 0.9300"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e79c8a6f3445>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m398\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_point_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         class_weight=[0.7880542, 0.84201391, 1.05645948, 0.94926901, 18.17903545])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Create a Keras Model\n",
    "    model = seg_hrnet(1, IMG_WIDTH, IMG_HEIGHT, 3, NB_CLASS)\n",
    "    model.summary()\n",
    "\n",
    "    # 优化器函数\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[f1, 'acc'])\n",
    "\n",
    "    # 获取路径列表\n",
    "    train_crop_top_paths, test_crop_top_paths = get_data_paths(TRAIN_TOP_PATH, VAL_TOP_PATH)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint('hrnet_superpixel.hdf5', monitor='val_f1', mode='max', verbose=1, save_best_only=True)\n",
    "    early_stop = EarlyStopping(monitor='val_f1', mode='max', patience=20)\n",
    "    check_point_list = [model_checkpoint, early_stop]\n",
    "\n",
    "    result = model.fit_generator(\n",
    "        generator=batch_generator(train_crop_top_paths, 1),\n",
    "        steps_per_epoch=10196,\n",
    "        epochs=500,\n",
    "        verbose=1,\n",
    "        validation_data=batch_generator(test_crop_top_paths, 1),\n",
    "        validation_steps=398,\n",
    "        callbacks=check_point_list,\n",
    "        class_weight=[0.7880542, 0.84201391, 1.05645948, 0.94926901, 18.17903545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(result.epoch, result.history['f1'], label=\"acc\")\n",
    "plt.plot(result.epoch, result.history['val_f1'], label=\"val_acc\")\n",
    "plt.scatter(result.epoch, result.history['f1'], marker='*')\n",
    "plt.scatter(result.epoch, result.history['val_f1'])\n",
    "plt.legend(loc='under right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(result.epoch, result.history['loss'], label=\"loss\")\n",
    "plt.plot(result.epoch, result.history['val_loss'], label=\"val_loss\")\n",
    "plt.scatter(result.epoch, result.history['loss'], marker='*')\n",
    "plt.scatter(result.epoch, result.history['val_loss'], marker='*')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "with open('unet_resnet_101.txt', 'w') as f:\n",
    "    f.write(str(result.history))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
